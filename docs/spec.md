## üìÅ Repository layout (top‚Äëlevel)

```
/docs/
  spec.md                       # v2 Application Specification (canonical)
  implementation-plan.md        # v2 Implementation Plan (canonical)
  expert-coder-guidance.md      # v2 Expert Coder Guidance (canonical)
  pseudocode-reference.md       # v2 Pseudocode Reference (canonical)

/src/                           # app source (scaffolds listed later)
/scripts/                       # scripts (schema, ci, ops, test helpers)
/tests/                         # phase- & task-aligned tests (NO MOCKS)
/reports/                       # test artifacts generated by CI and local runs
  phase-1/
  phase-2/
  phase-3/
  phase-4/
  phase-5/

.github/
  pull_request_template.md
  workflows/ci.yml

Makefile
docker-compose.yml
config/*.yaml
```

---

# 1) `/docs/spec.md` ‚Äî **WekaDocs GraphRAG MCP ‚Äî Application Specification (v2, canonical)**

**Status:** Canonical v2. Supersedes all prior versions.

### 0) Purpose & scope

WekaDocs GraphRAG MCP is a secure, explainable documentation intelligence layer that lets LLMs query a **Neo4j** knowledge graph enriched with **vector search**. It ingests Markdown/HTML/Notion docs into a **provenance‚Äëfirst** graph (`Document ‚Üí Section ‚Üí Entities`) and answers complex technical questions via **hybrid retrieval** (semantic + graph), **safe, parameterized Cypher** (templates‚Äëfirst + validator + `EXPLAIN` plan checks), and **structured responses** (Markdown + JSON with evidence and confidence).

---

## 1) Goals & non‚Äëgoals

**Goals**

* Evidence‚Äëbacked answers with citations down to **Section** granularity.
* Deterministic, idempotent ingestion with incremental updates and rollback.
* P95 latency < **500ms** for common queries (warmed caches).
* Defense‚Äëin‚Äëdepth: injection resistance, plan‚Äëgated Cypher, rate‚Äëlimits.

**Non‚Äëgoals**

* General web search; document editing UX; multi‚Äëtenant isolation beyond single org.

---

## 2) Architecture (high level)

```
LLM Client (MCP) ‚Üí FastAPI MCP Server
  ‚îú‚îÄ Tools Registry (Search / Traverse / Compare / Troubleshoot / Explain)
  ‚îú‚îÄ Query Planner (Templates-first; optional LLM proposal)
  ‚îú‚îÄ Cypher Validator (regex guard + parameterization + EXPLAIN plan gates)
  ‚îú‚îÄ Hybrid Retrieval (Vector + Graph; ranker)
  ‚îú‚îÄ Response Builder (Markdown + JSON + Evidence + Confidence)
  ‚îú‚îÄ Auth + Rate Limits + Audit
  ‚îú‚îÄ Cache (L1 in-proc, L2 Redis)
  ‚îî‚îÄ OpenTelemetry Tracing + Metrics

Ingestion Worker
  ‚îú‚îÄ Parsers (Markdown/HTML/Notion ‚Üí Document/Section)
  ‚îú‚îÄ Entity Extractors (Command/Configuration/Procedure/Error/Concept/Example/Step/Parameter)
  ‚îú‚îÄ Graph Builder (MERGE by deterministic IDs; provenance on all edges)
  ‚îú‚îÄ Embeddings (configurable model/dims)
  ‚îú‚îÄ Vector Upsert (Primary store: Qdrant OR Neo4j vectors; dual-write optional)
  ‚îî‚îÄ Reconciliation & Drift Repair

Storage: Neo4j 5.x (+ APOC/GDS), Qdrant (optional primary), Redis
```

---

## 3) Data model (v2, provenance‚Äëfirst)

### 3.1 Node labels

* **Document** `{id, source_uri, source_type, title, version, checksum, last_edited}`
* **Section** `{id, document_id, level, title, anchor, order, text, tokens, checksum, vector_embedding?, embedding_version?}`
* **Domain entities:** `Command, Configuration, Procedure, Error, Concept, Example, Step, Parameter, Component`
  *(All domain nodes share `{id, name|title|term..., description?, category?, introduced_in?, deprecated_in?, updated_at, vector_embedding?, embedding_version?}`)*

### 3.2 Relationships (all with provenance)

* `(Document)-[:HAS_SECTION {order}]->(Section)`
* `(Section)-[:MENTIONS {confidence, start, end, source_section_id}]->(Entity)`
* Derived edges (each has `derived_from_section_id`, `confidence`):
  `REQUIRES, AFFECTS, RESOLVES, CONTAINS_STEP{order}, EXECUTES, RELATED_TO, HAS_PARAMETER, DEPENDS_ON, EQUIVALENT_TO`

### 3.3 IDs, versions, consistency

* Deterministic IDs (SHA‚Äë256) from normalized tuples (`source_uri`, `anchor`, `text`, etc.).
* `schema_version` singleton; caches & vectors **prefixed** with `{schema_version}:{embedding_version}`.
* Embedding config is dynamic (`model_name`, `dims`, `similarity`, `multilingual`, `version`).

---

## 4) Retrieval & query planning

* **Templates‚Äëfirst** NL‚ÜíCypher; LLM proposal only as fallback; **never execute raw**.
* **Parameterization only**; reject literal user inputs in `WHERE`.
* **Validator**: regex guardrails + **`EXPLAIN` plan inspection** to cap label scans, expansions, depth; enforce **timeouts** and **LIMITs** early.


### 4.1 Hybrid retrieval

1. **Vector seed** search over **Section** (and optionally Entity) embeddings.
2. **Controlled graph expansion** (1‚Äì2 hops; typed edges only).
3. **Connecting paths** (bounded `shortestPath`).
4. **Ranking** by semantic score, path proximity, entity priority, recency (`Document.last_edited`), and coverage.

### 4.2 Query planning & safety

* **Templates first** (intent ‚Ü¶ pre‚Äëapproved Cypher).
* LLM‚Äëgenerated Cypher only as fallback ‚Üí pass through **validator**:

  * Regex guards + **parameterization enforcement**
  * **EXPLAIN** plan inspection: reject NodeByLabelScan and Expand(All) beyond thresholds; cap estimated rows/hops; enforce timeouts.
* Hard caps: traversal depth, result size, server‚Äëside timeouts.

---

## 5) Responses & explainability

* Dual output:

  * **Markdown** for humans.
  * **JSON** `{answer, evidence[{section_id, path}], confidence, diagnostics{ranking_features}}`.
* ‚Äú**Why these results?**‚Äù surface ranking features.
* **Disambiguation** card for homonyms.

---

## 6) Security

JWT auth; per‚Äëclient rate limits (Redis token bucket); audit logging (query hash, params hash, plan stats); TLS/mTLS; secrets via K8s/Docker secrets or Vault; parameterized Cypher only.

---

## 7) Observability & SLOs

OpenTelemetry tracing (FastAPI, Neo4j driver, vector calls). Metrics: P50/P95/P99 latency, cache hit/miss, slow Cypher, vector latency, queue lag, reconciliation drift.
**Targets:** P50<200ms, P95<500ms, P99<2s; availability 99.9%.

---

## 8) Ingestion pipeline

1. Parse ‚Üí `Document/Section`; preserve headings, anchors, code, tables; compute checksums.
2. Chunking: **Section** is primary chunk; split only when very long; use **title trail**.
3. Extract entities; write `MENTIONS` with spans + confidence.
4. MERGE graph (deterministic IDs) in batches with timeouts.
5. Embeddings (configurable) ‚Üí **primary vector store** (Qdrant *or* Neo4j); **dual‚Äëwrite** optional behind a flag.
6. Nightly reconciliation (graph vs vector) + drift repair.

---

## 9) Interfaces

**MCP tools:** `search_documentation`, `traverse_relationships`, `compare_systems`, `troubleshoot_error`, `explain_architecture`, plus utilities `disambiguate`, `explain_ranking`, `show_path`, `list_configs_affecting`.
**HTTP:** `/mcp`, `/health`, `/ready`, `/metrics` (auth & rate‚Äëlimited where appropriate).

---

## 10) Phases & tasks (alignment key)

* **Phase 1 ‚Äì Core Infrastructure**: **1.1** Docker env ¬∑ **1.2** MCP server ¬∑ **1.3** DB schema ¬∑ **1.4** Security
* **Phase 2 ‚Äì Query Processing Engine**: **2.1** NL‚ÜíCypher ¬∑ **2.2** Validator ¬∑ **2.3** Hybrid search ¬∑ **2.4** Response gen
* **Phase 3 ‚Äì Ingestion Pipeline**: **3.1** Parsers ¬∑ **3.2** Extraction ¬∑ **3.3** Graph build ¬∑ **3.4** Incremental
* **Phase 4 ‚Äì Advanced Query Features**: **4.1** Complex templates ¬∑ **4.2** Optimization ¬∑ **4.3** Caching ¬∑ **4.4** Learning
* **Phase 5 ‚Äì Integration & Deployment**: **5.1** External systems ¬∑ **5.2** Monitoring ¬∑ **5.3** Testing framework ¬∑ **5.4** Prod deploy

* **Phase 1 ‚Äì Core Infrastructure**
  1.1 Docker environment setup
  1.2 MCP server foundation
  1.3 Database schema initialization
  1.4 Security layer

* **Phase 2 ‚Äì Query Processing Engine**
  2.1 NL‚ÜíCypher translation
  2.2 Cypher validation system
  2.3 Hybrid search
  2.4 Response generation

* **Phase 3 ‚Äì Ingestion Pipeline**
  3.1 Multi‚Äëformat parser
  3.2 Entity extraction
  3.3 Graph construction
  3.4 Incremental update

* **Phase 4 ‚Äì Advanced Query Features**
  4.1 Complex query patterns
  4.2 Query optimization
  4.3 Caching & performance
  4.4 Learning & adaptation

* **Phase 5 ‚Äì Integration & Deployment**
  5.1 External systems
  5.2 Monitoring & observability
  5.3 Testing framework
  5.4 Production deployment

---

## 11) Success criteria & risks

* Evidence & confidence on every answer.
* Validator rejects unsafe plans; caches versioned; drift <0.5% daily.
* Chaos tests for vector outage, Neo4j backpressure, cache poisoning.
  Key risks: query complexity explosion, drift, performance regressions ‚Äî mitigated via guardrails, reconciliation, dashboards & alerts.

  **Evidence** attached to every answer; **confidence** score in [0,1].
* **Dual‚Äëstore clarity** (declare SoT; dual‚Äëwrite behind a flag).
* **Validator** rejects unsafe plans (EXPLAIN‚Äëbased).
* **Chaos tests** for vector outage, Neo4j backpressure, cache poisoning.
* **Drift** alerts if graph/vector mismatch > 0.5% of sections.

---

## 12) Phase gates (no‚Äëmocks testing required)

Each phase must **produce and attach** machine‚Äëreadable test results under `/reports/phase-N/summary.json` and JUnit XML under `/reports/phase-N/junit.xml`. **No mocks anywhere.** Gates block promotion until all criteria pass:

* **Gate P1 ‚Üí P2:** infra green; auth/rate‚Äëlimit enforced; schema created; tracing on; **tests** for health, auth, rate limiting, schema idempotency all pass; artifacts saved.
* **Gate P2 ‚Üí P3:** validator blocks attacks; hybrid search P95 < 500ms (warmed); responses include evidence & confidence; artifacts saved.
* **Gate P3 ‚Üí P4:** ingestion deterministic; incremental update limited to changed sections; reconciliation drift < 0.5%; artifacts saved.
* **Gate P4 ‚Üí P5:** advanced templates pass guardrails; cache hit > 80% steady; artifacts saved.
* **Gate P5 ‚Üí Launch:** full test matrix green; monitoring/alerts live; DR drill passes; artifacts saved.
