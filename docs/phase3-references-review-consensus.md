# Phase 3 REFERENCES Implementation - Multi-Model Consensus Review

**Generated**: 2025-11-30
**Branch**: `dense-graph-enhance`
**Status**: Review Complete - 28 Issues Identified

---

## Executive Summary

A comprehensive multi-model review was conducted on the Phase 3 REFERENCES implementation using:
- **3 Code Reviews** (o3, gpt-5.1-codex, gemini-3-pro-preview)
- **2 Architecture Analyses** (o3, gemini-3-pro-preview)
- **1 Trace Verification** (gpt-5.1-codex)

### Key Finding

**The feature is effectively dead code.** The query layer traverses `Documentâ†’Document` edges, but ingestion creates `Chunkâ†’Document` edges. This fundamental mismatch means cross-document signals always return zero results.

### Statistics

| Metric | Value |
|--------|-------|
| Models Consulted | 3 |
| Confidence Range | 6/10 - 10/10 (avg: 7.7/10) |
| Total Unique Issues | 28 (after deduplication) |
| CRITICAL Issues | 8 |
| HIGH Issues | 7 |
| MEDIUM Issues | 7 |
| LOW Issues | 6 |

---

## Unanimous Agreement (All 3 Models)

All models **unanimously agree** on these critical findings:

1. **Feature is dead code** - Query traversal pattern doesn't match ingested edges
2. **Ghost ID collision** - CJK/emoji titles all map to `ghost::unknown`
3. **Query fix is #1 priority** - Must be fixed before any other work matters
4. **Feature flag required** - Cannot safely ship without kill switch

---

## Final Consolidated Findings Table

| Order | Severity | Issue | Location | Proposed Fix |
|:-----:|:--------:|-------|----------|--------------|
| 1 | CRITICAL | Query Traversal Mismatch | `hybrid_retrieval.py:2084-2089` | Rewrite to start from Chunk |
| 2 | CRITICAL | Ghost ID Collision | `references.py:67-73` | SHA hash fallback |
| 3 | CRITICAL | Fuzzy Scan Bottleneck | `atomic.py:1752-1762` | Use fulltext index |
| 4 | CRITICAL | Ghost Resolution Race | `atomic.py:1422-1428` | Coalesce or APOC lock |
| 5 | CRITICAL | PendingReference Same Race | `atomic.py:1472-1479` | Same CAS fix |
| 6 | CRITICAL | Large Batch TX Timeout | `atomic.py:1799-1894` | Batch chunking |
| 7 | CRITICAL | ReDoS Incomplete | `references.py:100-125` | Atomic groups/timeout |
| 8 | CRITICAL | Feature Flag Missing | Multiple files | Add config flag |
| 9 | HIGH | 8KB Truncation Drops Refs | `references.py:155-162` | Windowed scanning |
| 10 | HIGH | Acronym Destruction | `references.py:246` | Preserve all-caps |
| 11 | HIGH | Batch Memory Spike | `atomic.py:1681-1894` | Generator streaming |
| 12 | HIGH | No Rollback on Partial Fail | `atomic.py:1799-1902` | Compensating transactions |
| 13 | HIGH | Empty Title Skipped | `atomic.py:1405-1406` | Filename fallback |
| 14 | HIGH | Errors Swallowed | Multiple locations | Narrow exceptions |
| 15 | HIGH | Config Hardcoded | Multiple files | Move to settings |
| 16 | MEDIUM | Dual Labels Confuse Queries | `atomic.py:1829` | Single label only |
| 17 | MEDIUM | Source Allows Document | `atomic.py:1801-1802` | Chunk-only source |
| 18 | MEDIUM | Locale Mismatch | `atomic.py:1729` | ICU normalization |
| 19 | MEDIUM | Regex Groups Fragile | `references.py:110-124` | Named groups |
| 20 | MEDIUM | Unsanitized Logs | `atomic.py:1899` | Escape/truncate |
| 21 | MEDIUM | Fuzzy Penalty Fixed | `atomic.py:1776` | Move to config |
| 22 | MEDIUM | No Query Feature Flag | `hybrid_retrieval.py:2073` | Add config option |
| 23 | LOW | Dict Order Implicit | `references.py:102` | Document or use list |
| 24 | LOW | Stale Schema Provider | `schema.cypher:367` | Update to bge-m3 |
| 25 | LOW | Magic Numbers | Multiple locations | Add constants |
| 26 | LOW | Metric Namespace Collision | `atomic.py` | Add prefix |
| 27 | LOW | Entity Extractor Unnecessary | `hybrid_retrieval.py:2164` | Short-circuit |
| 28 | LOW | No E2E Integration Test | `tests/` | Add regression test |

---

## Detailed Fixes

### Fix #1: Query Traversal Mismatch

**Severity**: CRITICAL
**Location**: `src/query/hybrid_retrieval.py:2084-2089`
**Effort**: 2 hours

#### Current Code (Broken)

```python
cypher = """
// Start with candidate chunks that have REFERENCES edges
UNWIND $chunk_ids AS seed_id
MATCH (seed:Chunk {id: seed_id})
// Get the document containing this seed chunk
MATCH (seed_doc:Document)-[:HAS_CHUNK]->(seed)
// Find documents that seed_doc REFERENCES
MATCH (seed_doc)-[:REFERENCES]->(ref_doc:Document)  // <-- WRONG: Doc->Doc doesn't exist!
WHERE NOT ref_doc:GhostDocument
// Get chunks from the referenced document that are also candidates
MATCH (ref_doc)-[:HAS_CHUNK]->(related:Chunk)
WHERE related.id IN $chunk_ids
  AND related.id <> seed_id
  AND ($doc_tag IS NULL OR related.doc_tag = $doc_tag)
RETURN related.id AS chunk_id,
       count(DISTINCT seed_doc) AS ref_count,
       collect(DISTINCT seed_doc.title)[..3] AS referencing_docs
"""
```

#### Fixed Code

```python
cypher = """
// Start with candidate chunks that have REFERENCES edges
UNWIND $chunk_ids AS seed_id
MATCH (seed:Chunk {id: seed_id})
// Follow REFERENCES from the chunk directly to target document
MATCH (seed)-[:REFERENCES]->(ref_doc:Document)  // <-- FIXED: Chunk->Doc
WHERE NOT ref_doc:GhostDocument
// Get chunks from the referenced document that are also candidates
MATCH (ref_doc)-[:HAS_CHUNK]->(related:Chunk)
WHERE related.id IN $chunk_ids
  AND related.id <> seed_id
  AND ($doc_tag IS NULL OR related.doc_tag = $doc_tag)
RETURN related.id AS chunk_id,
       count(DISTINCT seed) AS ref_count,
       collect(DISTINCT seed.document_id)[..3] AS referencing_docs
"""
```

#### Why This Fix

Ingestion creates edges with pattern `(Chunk)-[:REFERENCES]->(Document)`:
- `atomic.py:1804` creates resolved refs from Chunk
- `atomic.py:1838` creates ghost refs from Chunk

But the query was looking for `(Document)-[:REFERENCES]->(Document)` which **don't exist**.

The fix changes the traversal to match what ingestion actually creates.

---

### Fix #2: Ghost ID Collision

**Severity**: CRITICAL
**Location**: `src/ingestion/extract/references.py:67-73`
**Effort**: 1 hour

#### Current Code (Broken)

```python
def slugify_for_id(text: str) -> str:
    """
    Create deterministic, ASCII-safe slug for use in IDs.
    """
    if not text:
        return "unknown"

    # NFKD normalization decomposes characters (e.g., Ã± â†’ n + combining tilde)
    normalized = unicodedata.normalize("NFKD", text)
    # Encode to ASCII, dropping non-ASCII characters (accents, CJK, etc.)
    ascii_text = normalized.encode("ascii", "ignore").decode("ascii")
    # Lowercase and strip
    slug = ascii_text.lower().strip()
    # Replace non-alphanumeric sequences with hyphens
    slug = _SLUG_RE.sub("-", slug).strip("-")

    return slug if slug else "unknown"  # <-- BUG: CJK titles all become "unknown"!
```

#### Fixed Code

```python
import hashlib

def slugify_for_id(text: str) -> str:
    """
    Create deterministic, ASCII-safe slug for use in IDs.

    For non-ASCII titles (CJK, emoji, etc.), uses SHA-256 hash to ensure
    uniqueness instead of colliding on "unknown".
    """
    if not text:
        return "unknown"

    # NFKD normalization decomposes characters (e.g., Ã± â†’ n + combining tilde)
    normalized = unicodedata.normalize("NFKD", text)
    # Encode to ASCII, dropping non-ASCII characters (accents, CJK, etc.)
    ascii_text = normalized.encode("ascii", "ignore").decode("ascii")
    # Lowercase and strip
    slug = ascii_text.lower().strip()
    # Replace non-alphanumeric sequences with hyphens
    slug = _SLUG_RE.sub("-", slug).strip("-")

    # Fix #2: Use hash fallback for non-ASCII titles to prevent collisions
    if not slug:
        # SHA-256 hash ensures uniqueness for CJK/emoji titles
        slug = hashlib.sha256(text.encode("utf-8")).hexdigest()[:12]
        logger.debug("slugify_hash_fallback", original_text=text[:50], hash_slug=slug)

    return slug
```

#### Why This Fix

Pure CJK titles like "æ—¥æœ¬èªžãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ" get completely stripped by ASCII encoding, resulting in empty string â†’ "unknown".

This causes **all non-ASCII titles to collide** on the same ghost ID `ghost::unknown`, corrupting the graph by merging unrelated forward references.

The SHA-256 hash fallback ensures every unique title produces a unique ghost ID.

**Examples**:
| Title | Before | After |
|-------|--------|-------|
| "Snapshot Policies" | `ghost::snapshot-policies` | `ghost::snapshot-policies` |
| "æ—¥æœ¬èªžãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ" | `ghost::unknown` | `ghost::a1b2c3d4e5f6` |
| "ä¸­æ–‡æ–‡æ¡£" | `ghost::unknown` | `ghost::7890abcdef12` |
| "Emoji Guide ðŸš€" | `ghost::emoji-guide` | `ghost::emoji-guide` |

---

### Fix #3: Fuzzy Scan Bottleneck

**Severity**: CRITICAL
**Location**: `src/ingestion/atomic.py:1752-1762`
**Effort**: 2 hours

#### Current Code (Broken)

```python
batch_fuzzy_query = """
UNWIND $hints AS hint
OPTIONAL MATCH (d:Document)
WHERE toLower(d.title) CONTAINS toLower(hint)  -- O(N) full table scan per hint!
WITH hint, d
ORDER BY size(d.title) ASC
WITH hint, collect(d.id)[0] AS doc_id
RETURN hint, doc_id
"""
```

#### Fixed Code

```python
batch_fuzzy_query = """
UNWIND $hints AS hint
CALL db.index.fulltext.queryNodes('document_title_ft', hint)
YIELD node AS d, score
WHERE score > 0.5  // Relevance threshold
WITH hint, d, score
ORDER BY score DESC, size(d.title) ASC
WITH hint, collect(d.id)[0] AS doc_id
RETURN hint, doc_id
"""
```

#### Schema Requirement

Add to `scripts/neo4j/create_graphrag_schema_v2_2_*.cypher`:

```cypher
// Fulltext index for fuzzy title matching
CALL db.index.fulltext.createNodeIndex(
  'document_title_ft',
  ['Document'],
  ['title'],
  {analyzer: 'standard-folding'}
) IF NOT EXISTS;
```

#### Why This Fix

`CONTAINS` with `toLower()` forces Neo4j to:
1. Load every Document node
2. Apply toLower() to each title
3. Check if it contains the hint

This is O(N) for **every hint** in the batch, giving O(N Ã— M) total complexity where N = documents, M = hints.

With 10,000 documents and 50 hints, that's 500,000 string comparisons per ingestion.

The fulltext index uses an inverted index structure for O(log N) lookup per hint.

---

### Fix #4: Ghost Resolution Race Condition

**Severity**: CRITICAL
**Location**: `src/ingestion/atomic.py:1422-1428`
**Effort**: 1.5 hours

#### Current Code (Broken)

```cypher
MATCH (ghost:GhostDocument)
WHERE toLower(ghost.title) = toLower($title)
// Atomic lock acquisition - SET is atomic in Neo4j
SET ghost._resolve_lock = $doc_id
WITH ghost
// Verify we successfully acquired the lock (another tx may have won)
WHERE ghost._resolve_lock = $doc_id
```

#### Problem

The comment claims SET is atomic, but the **check-then-act** pattern has a race:

1. Transaction A: `SET ghost._resolve_lock = 'doc_a'`
2. Transaction B: `SET ghost._resolve_lock = 'doc_b'` (overwrites!)
3. Transaction A: `WHERE ghost._resolve_lock = 'doc_a'` â†’ **fails** (now 'doc_b')
4. Transaction B: `WHERE ghost._resolve_lock = 'doc_b'` â†’ passes
5. **Result**: Only B resolves, A silently fails

But worse, both could pass if timing aligns:

1. Transaction A: SET â†’ sees 'doc_a'
2. Transaction A: WHERE â†’ passes (still 'doc_a')
3. Transaction B: SET â†’ overwrites to 'doc_b'
4. Transaction B: WHERE â†’ passes (now 'doc_b')
5. **Result**: Both try to resolve same ghost â†’ data corruption

#### Fixed Code (Option A: Coalesce Pattern)

```cypher
MATCH (ghost:GhostDocument)
WHERE toLower(ghost.title) = toLower($title)
  AND ghost._resolve_lock IS NULL  -- Only claim unlocked ghosts
SET ghost._resolve_lock = $doc_id
WITH ghost
WHERE ghost._resolve_lock = $doc_id  -- Verify we won
```

This works because:
- `ghost._resolve_lock IS NULL` filters before SET
- If another tx already set it, this tx won't match
- Only one tx can SET on a previously-NULL value

#### Fixed Code (Option B: APOC Pessimistic Locking)

```cypher
MATCH (ghost:GhostDocument)
WHERE toLower(ghost.title) = toLower($title)
CALL apoc.lock.nodes([ghost])  -- Explicit pessimistic lock
SET ghost._resolve_lock = $doc_id
WITH ghost
// ... rest of resolution ...
```

This uses APOC's explicit locking to serialize access.

---

### Fix #5: PendingReference Same Race

**Severity**: CRITICAL
**Location**: `src/ingestion/atomic.py:1472-1479`
**Effort**: 30 minutes (same fix as #4)

#### Current Code (Broken)

```cypher
MATCH (pending:PendingReference)
WHERE toLower($title) CONTAINS toLower(pending.hint)
   OR toLower(pending.hint) CONTAINS toLower($title)
SET pending._resolve_lock = $doc_id
WITH pending
WHERE pending._resolve_lock = $doc_id
```

#### Fixed Code

```cypher
MATCH (pending:PendingReference)
WHERE (toLower($title) CONTAINS toLower(pending.hint)
   OR toLower(pending.hint) CONTAINS toLower($title))
  AND pending._resolve_lock IS NULL  -- Only claim unlocked
SET pending._resolve_lock = $doc_id
WITH pending
WHERE pending._resolve_lock = $doc_id
```

---

### Fix #6: Large Batch TX Timeout

**Severity**: CRITICAL
**Location**: `src/ingestion/atomic.py:1799-1894`
**Effort**: 2 hours

#### Current Code (Broken)

```python
# All refs processed in single UNWIND - can be 1000+ items
if resolved_refs:
    batch_create_query = """
    UNWIND $refs AS ref
    MATCH (src {id: ref.source_chunk_id})
    WHERE src:Chunk OR src:Document
    MATCH (d:Document {id: ref.target_doc_id})
    MERGE (src)-[r:REFERENCES]->(d)
    ...
    """
    result = tx.run(batch_create_query, refs=resolved_refs)  # Could be 500+ refs!
```

#### Fixed Code

```python
BATCH_SIZE = 100  # Configurable via config.references.resolution.batch_size

def _neo4j_create_references(self, tx, references: List[Dict]) -> int:
    # ... categorization logic unchanged ...

    created_count = 0

    # Batch resolved refs
    for i in range(0, len(resolved_refs), BATCH_SIZE):
        batch = resolved_refs[i:i + BATCH_SIZE]
        result = tx.run(batch_create_query, refs=batch)
        record = result.single()
        if record:
            created_count += record["created"]
        logger.debug("resolved_batch_complete",
                     batch_num=i // BATCH_SIZE + 1,
                     batch_size=len(batch),
                     running_total=created_count)

    # Batch ghost refs
    for i in range(0, len(ghost_refs), BATCH_SIZE):
        batch = ghost_refs[i:i + BATCH_SIZE]
        result = tx.run(batch_ghost_query, refs=batch)
        record = result.single()
        if record:
            created_count += record["created"]

    # Batch pending refs
    for i in range(0, len(pending_refs), BATCH_SIZE):
        batch = pending_refs[i:i + BATCH_SIZE]
        result = tx.run(batch_pending_query, refs=batch)
        record = result.single()
        if record:
            # pending_count tracked separately
            pass

    return created_count
```

#### Why This Fix

Neo4j has a default transaction timeout (typically 60 seconds). A single UNWIND with 500+ items that each:
- MATCH source node
- MATCH target document
- MERGE relationship
- SET multiple properties

Can easily exceed this timeout, especially under concurrent load when locks are contended.

Batching into 100-item chunks:
- Keeps each operation fast
- Reduces lock hold time
- Allows progress tracking
- Makes partial failures more recoverable

---

### Fix #7: ReDoS Incomplete Protection

**Severity**: CRITICAL
**Location**: `src/ingestion/extract/references.py:100-125`
**Effort**: 2 hours

#### Current Code (Vulnerable)

```python
REFERENCE_PATTERNS = {
    "hyperlink": re.compile(
        r"\[([^\]]+)\]\(([^)]+\.md)\)", re.IGNORECASE
    ),
    "see_also": re.compile(
        r"see\s+(?:also)?:?\s*\[([^\]]+)\]\([^)]+\)|"
        r"see\s+(?:also)?:?\s+([A-Z][^\n\.\,]+?)(?:\s*[-â€“â€”]|$|\n|\.)",
        re.MULTILINE | re.IGNORECASE,
    ),
    "related": re.compile(
        r"related:?\s*\[([^\]]+)\]\([^)]+\)|"
        r"related:?\s+([A-Z][^\n\.\,]+?)(?:\s*[-â€“â€”]|$|\n)",
        re.MULTILINE | re.IGNORECASE,
    ),
    "refer_to": re.compile(
        r"(?:refer\s+to|see)\s+(?:the\s+)?([A-Z][^\.\n]+?(?:Guide|Manual|Doc|Documentation|Configuration))",
        re.MULTILINE | re.IGNORECASE,
    ),
}
```

The 8KB truncation helps, but patterns like `[^\n\.\,]+?` can still backtrack significantly on pathological input.

#### Fixed Code (Option A: Possessive Quantifiers - Python 3.11+)

```python
REFERENCE_PATTERNS = {
    "hyperlink": re.compile(
        r"\[([^\]]+)\]\(([^)]+\.md)\)", re.IGNORECASE
    ),
    "see_also": re.compile(
        r"see\s+(?:also)?:?\s*\[([^\]]+)\]\([^)]+\)|"
        r"see\s+(?:also)?:?\s+([A-Z][^\n\.\,]{0,200}+)(?:\s*[-â€“â€”]|$|\n|\.)",  # Possessive + length limit
        re.MULTILINE | re.IGNORECASE,
    ),
    "related": re.compile(
        r"related:?\s*\[([^\]]+)\]\([^)]+\)|"
        r"related:?\s+([A-Z][^\n\.\,]{0,200}+)(?:\s*[-â€“â€”]|$|\n)",  # Possessive + length limit
        re.MULTILINE | re.IGNORECASE,
    ),
    "refer_to": re.compile(
        r"(?:refer\s+to|see)\s+(?:the\s+)?([A-Z][^\.\n]{0,200}+(?:Guide|Manual|Doc|Documentation|Configuration))",
        re.MULTILINE | re.IGNORECASE,
    ),
}
```

#### Fixed Code (Option B: Timeout-based using `regex` library)

```python
import regex  # pip install regex - drop-in replacement with timeout support

def extract_references(text: str, source_chunk_id: str) -> List[Reference]:
    if not text:
        return []

    # Truncate for safety (keep existing protection)
    if len(text) > MAX_TEXT_LENGTH_FOR_REGEX:
        logger.debug("text_truncated_for_regex",
                     source_chunk_id=source_chunk_id,
                     original_length=len(text))
        text = text[:MAX_TEXT_LENGTH_FOR_REGEX]

    references = []
    seen_targets = set()

    for ref_type, pattern in REFERENCE_PATTERNS.items():
        try:
            # Timeout after 1 second per pattern
            for match in pattern.finditer(text, timeout=1.0):
                # ... process match ...
                pass
        except regex.error as e:
            logger.warning("regex_timeout",
                          pattern=ref_type,
                          chunk_id=source_chunk_id,
                          error=str(e))
            continue  # Skip this pattern, try others

    return references
```

---

### Fix #8: Feature Flag Missing

**Severity**: CRITICAL
**Location**: Multiple files + new config
**Effort**: 1 hour

#### Add to `src/shared/config.py`

```python
from dataclasses import dataclass, field
from typing import Dict

@dataclass
class ReferencesExtractionConfig:
    max_text_length: int = 8192
    confidence_scores: Dict[str, float] = field(default_factory=lambda: {
        "hyperlink": 0.95,
        "see_also": 0.85,
        "related": 0.80,
        "refer_to": 0.70,
    })

@dataclass
class ReferencesResolutionConfig:
    fuzzy_penalty: float = 0.25
    batch_size: int = 100
    min_hint_length: int = 3  # Prevent short hints matching too broadly

@dataclass
class ReferencesQueryConfig:
    enable_cross_doc_signals: bool = True
    cross_doc_weight_ratio: float = 0.3

@dataclass
class ReferencesConfig:
    enabled: bool = False  # DISABLED BY DEFAULT until fixes verified
    extraction: ReferencesExtractionConfig = field(default_factory=ReferencesExtractionConfig)
    resolution: ReferencesResolutionConfig = field(default_factory=ReferencesResolutionConfig)
    query: ReferencesQueryConfig = field(default_factory=ReferencesQueryConfig)
```

#### Guard in `src/ingestion/atomic.py`

```python
def _prepare_references(self, document: Dict, chunks: List[Dict],
                        known_titles: Dict[str, str]) -> List[Dict]:
    """Extract references from chunks if feature is enabled."""
    if not self.config.references.enabled:
        logger.debug("references_disabled", document_id=document.get("id"))
        return []

    return extract_chunk_references(
        chunks,
        known_titles,
        deduplicate_across_chunks=True
    )
```

#### Guard in `src/query/hybrid_retrieval.py`

```python
def _compute_cross_doc_signals(
    self,
    candidate_chunk_ids: List[str],
    query_type: str,
    doc_tag: Optional[str],
) -> Dict[str, Dict[str, Any]]:
    """Compute cross-document signals via REFERENCES edge traversal."""
    # Feature flag check
    if not getattr(self.config, 'references', None):
        return {}
    if not self.config.references.enabled:
        return {}
    if not self.config.references.query.enable_cross_doc_signals:
        return {}

    # ... rest of method ...
```

#### Environment Variable Override

```bash
# Disable in production until fixes verified
export REFERENCES_ENABLED=false

# Enable for testing
export REFERENCES_ENABLED=true
```

---

### Fix #9: 8KB Truncation Drops Refs

**Severity**: HIGH
**Location**: `src/ingestion/extract/references.py:155-162`
**Effort**: 1.5 hours

#### Current Code (Data Loss)

```python
def extract_references(text: str, source_chunk_id: str) -> List[Reference]:
    if not text:
        return []

    # M6: ReDoS protection - truncate large texts before regex matching
    if len(text) > MAX_TEXT_LENGTH_FOR_REGEX:
        logger.debug("text_truncated_for_regex", ...)
        text = text[:MAX_TEXT_LENGTH_FOR_REGEX]  # References after 8KB silently dropped!

    # ... extraction ...
```

#### Fixed Code (Windowed Approach)

```python
def extract_references(text: str, source_chunk_id: str) -> List[Reference]:
    """
    Extract cross-document references from text.

    Uses windowed processing to handle documents larger than MAX_TEXT_LENGTH_FOR_REGEX
    without silently dropping references.
    """
    if not text:
        return []

    references = []
    seen_targets = set()  # Deduplicate across windows

    # Process in overlapping windows to catch refs at boundaries
    window_size = MAX_TEXT_LENGTH_FOR_REGEX
    overlap = 512  # Overlap to catch refs split across windows

    total_windows = max(1, (len(text) - overlap) // (window_size - overlap) + 1)

    for window_idx, start in enumerate(range(0, len(text), window_size - overlap)):
        window = text[start:start + window_size]

        for ref_type, pattern in REFERENCE_PATTERNS.items():
            confidence = CONFIDENCE_SCORES[ref_type]

            for match in pattern.finditer(window):
                # Extract target hint
                target_hint = _extract_target_hint(match, ref_type)
                if not target_hint:
                    continue

                # Deduplicate across windows
                normalized_hint = target_hint.lower().strip()
                if normalized_hint in seen_targets:
                    continue
                seen_targets.add(normalized_hint)

                # Adjust offsets for window position
                references.append(
                    Reference(
                        reference_type=ref_type,
                        reference_text=match.group(0),
                        target_hint=target_hint,
                        confidence=confidence,
                        start=start + match.start(),
                        end=start + match.end(),
                    )
                )

    if total_windows > 1:
        logger.info("text_processed_in_windows",
                    source_chunk_id=source_chunk_id,
                    total_length=len(text),
                    window_count=total_windows,
                    references_found=len(references))

    return references
```

---

### Fix #10: Acronym Destruction

**Severity**: HIGH
**Location**: `src/ingestion/extract/references.py:246`
**Effort**: 1 hour

#### Current Code (Breaks Acronyms)

```python
def normalize_filename_to_title(filename: str) -> str:
    # Strip fragments and paths
    if "#" in filename:
        filename = filename.split("#")[0]
    if "/" in filename:
        filename = filename.split("/")[-1]

    # Remove .md extension
    name = filename.replace(".md", "").replace(".MD", "")
    # Replace hyphens/underscores with spaces
    name = name.replace("-", " ").replace("_", " ")
    # Title case - THIS BREAKS ACRONYMS!
    return name.title()  # "SMB" â†’ "Smb", "API" â†’ "Api"
```

#### Fixed Code (Preserves Acronyms)

```python
from urllib.parse import unquote
import re

def normalize_filename_to_title(filename: str) -> str:
    """
    Convert a markdown filename to a likely document title.

    Preserves acronyms (all-caps tokens) and handles URL encoding.

    Examples:
        "smb-configuration.md" -> "Smb Configuration"
        "SMB-configuration.md" -> "SMB Configuration"
        "snapshot%20policies.md" -> "Snapshot Policies"
        "API-reference.md" -> "API Reference"
    """
    # Strip URL fragments (e.g., #section-name)
    if "#" in filename:
        filename = filename.split("#")[0]

    # Strip directory prefixes
    if "/" in filename:
        filename = filename.split("/")[-1]

    # URL decode (handle %20, etc.)
    filename = unquote(filename)

    # Remove .md extension (case-insensitive)
    name = re.sub(r"\.md$", "", filename, flags=re.IGNORECASE)

    # Split on separators
    tokens = re.split(r"[-_]+", name)

    # Normalize each token, preserving acronyms
    normalized = []
    for token in tokens:
        if not token:
            continue
        if token.isupper() and len(token) > 1:
            # Preserve acronyms: SMB, API, NFS, etc.
            normalized.append(token)
        elif token.islower():
            # Capitalize lowercase words
            normalized.append(token.capitalize())
        else:
            # Keep mixed case as-is: WekaFS, MacOS, etc.
            normalized.append(token)

    return " ".join(normalized)
```

---

### Fix #11: Batch Memory Spike

**Severity**: HIGH
**Location**: `src/ingestion/atomic.py:1681-1894`
**Effort**: 1.5 hours

#### Fixed Code (Generator-based)

```python
def _neo4j_create_references(self, tx, references: List[Dict]) -> int:
    """Create cross-document REFERENCES edges within a transaction."""
    if not references:
        return 0

    from src.ingestion.extract.references import normalize_filename_to_title, slugify_for_id

    BATCH_SIZE = self.config.references.resolution.batch_size

    # Use generator to avoid loading all categorized refs into memory
    def categorize_and_yield():
        for ref in references:
            source_chunk_id = ref.get("source_chunk_id")
            if not source_chunk_id:
                logger.warning("reference_missing_source_chunk",
                              target_hint=ref.get("target_hint", ""))
                continue

            ref_data = {
                "source_chunk_id": source_chunk_id,
                "target_doc_id": ref.get("target_doc_id"),
                "target_hint": ref.get("target_hint", ""),
                "reference_type": ref.get("reference_type", "unknown"),
                "reference_text": ref.get("reference_text", ""),
                "confidence": ref.get("confidence", 0.5),
                "is_fuzzy_match": False,
            }

            # Categorize
            if ref_data["target_doc_id"]:
                yield ("resolved", ref_data)
            elif ref_data["reference_type"] == "hyperlink" and ref_data["target_hint"].endswith(".md"):
                ref_data["possible_title"] = normalize_filename_to_title(ref_data["target_hint"])
                yield ("needs_title", ref_data)
            else:
                yield ("needs_fuzzy", ref_data)

    # Collect into batches and process
    resolved_batch = []
    title_batch = []
    fuzzy_batch = []
    created_count = 0

    for category, ref_data in categorize_and_yield():
        if category == "resolved":
            resolved_batch.append(ref_data)
        elif category == "needs_title":
            title_batch.append(ref_data)
        else:
            fuzzy_batch.append(ref_data)

        # Flush when batch full
        if len(resolved_batch) >= BATCH_SIZE:
            created_count += self._flush_resolved_batch(tx, resolved_batch)
            resolved_batch = []

    # Flush remaining
    if resolved_batch:
        created_count += self._flush_resolved_batch(tx, resolved_batch)

    # Process title and fuzzy batches...
    # (similar batched processing)

    return created_count

def _flush_resolved_batch(self, tx, batch: List[Dict]) -> int:
    """Flush a batch of resolved references to Neo4j."""
    if not batch:
        return 0

    query = """
    UNWIND $refs AS ref
    MATCH (src:Chunk {id: ref.source_chunk_id})
    MATCH (d:Document {id: ref.target_doc_id})
    MERGE (src)-[r:REFERENCES]->(d)
    ON CREATE SET
        r.type = ref.reference_type,
        r.reference_text = ref.reference_text,
        r.confidence = ref.confidence,
        r.target_hint = ref.target_hint,
        r.source_type = 'chunk',
        r.created_at = datetime({timezone: 'UTC'})
    RETURN count(r) AS created
    """
    result = tx.run(query, refs=batch)
    record = result.single()
    return record["created"] if record else 0
```

---

### Fix #12: No Rollback on Partial Fail

**Severity**: HIGH
**Location**: `src/ingestion/atomic.py:1799-1902`
**Effort**: 2 hours

#### Fixed Code (Compensating Transactions)

```python
def _neo4j_create_references(self, tx, references: List[Dict]) -> Dict[str, Any]:
    """
    Create cross-document REFERENCES edges within a transaction.

    Returns detailed result with counts and any errors for saga orchestration.
    """
    result = {
        "created": 0,
        "ghost_created": 0,
        "pending_created": 0,
        "errors": [],
        "created_ghost_ids": [],  # Track for rollback
        "created_edge_ids": [],   # Track for rollback
    }

    if not references:
        return result

    try:
        # Phase 1: Create resolved refs
        if resolved_refs:
            count, edge_ids = self._create_resolved_batch_tracked(tx, resolved_refs)
            result["created"] += count
            result["created_edge_ids"].extend(edge_ids)

        # Phase 2: Create ghost refs
        if ghost_refs:
            ghost_ids, count = self._create_ghost_batch_tracked(tx, ghost_refs)
            result["created_ghost_ids"].extend(ghost_ids)
            result["ghost_created"] += count

        # Phase 3: Create pending refs
        if pending_refs:
            count = self._create_pending_batch(tx, pending_refs)
            result["pending_created"] += count

    except Exception as e:
        logger.error("reference_creation_failed",
                    error=str(e),
                    created_so_far=result["created"],
                    ghost_created_so_far=result["ghost_created"])

        # Rollback: delete ghosts we created in this transaction
        if result["created_ghost_ids"]:
            self._rollback_ghosts(tx, result["created_ghost_ids"])
            logger.info("ghosts_rolled_back",
                       count=len(result["created_ghost_ids"]))

        result["errors"].append({
            "phase": "reference_creation",
            "error": str(e),
            "rollback_performed": bool(result["created_ghost_ids"])
        })
        raise  # Re-raise to trigger saga-level rollback

    return result

def _rollback_ghosts(self, tx, ghost_ids: List[str]):
    """Delete ghost documents created in a failed transaction."""
    if not ghost_ids:
        return

    query = """
    UNWIND $ghost_ids AS ghost_id
    MATCH (g:GhostDocument {id: ghost_id})
    DETACH DELETE g
    RETURN count(g) AS deleted
    """
    tx.run(query, ghost_ids=ghost_ids)
```

---

### Fix #13: Empty Title Skipped

**Severity**: HIGH
**Location**: `src/ingestion/atomic.py:1405-1406`
**Effort**: 30 minutes

#### Fixed Code

```python
def _neo4j_upsert_document(self, tx, document: Dict):
    """Upsert a document node within a transaction."""
    # ... existing upsert logic ...

    # Get title for resolution
    title = document.get("title", "")

    # Fix #13: Fallback to filename-derived title
    if not title:
        doc_id = document.get("id", "")
        if doc_id:
            # Derive title from document ID (usually contains filename)
            filename = doc_id.split("/")[-1]
            title = normalize_filename_to_title(filename)
            logger.warning("empty_title_fallback",
                          document_id=document["id"],
                          derived_title=title,
                          reason="document_missing_title")

    if title:
        # Phase 3: Resolve Ghost Documents with matching title
        self._resolve_ghost_documents(tx, title, document["id"])
        # Phase 3: Resolve PendingReferences with matching hint
        self._resolve_pending_references(tx, title, document["id"])
    else:
        logger.warning("document_unresolvable",
                      document_id=document["id"],
                      reason="no_title_or_fallback",
                      impact="ghost_refs_to_this_doc_will_remain_unresolved")
```

---

### Fix #14: Errors Swallowed

**Severity**: HIGH
**Location**: Multiple `try/except Exception` blocks
**Effort**: 1 hour

#### Before (Bad Pattern)

```python
try:
    result = tx.run(query, params)
    record = result.single()
except Exception as e:
    logger.warning("query_failed", error=str(e))
    return None  # Silent failure - caller doesn't know!
```

#### After (Good Pattern)

```python
from neo4j.exceptions import (
    TransientError,
    DatabaseError,
    ConstraintError,
    ServiceUnavailable
)

try:
    result = tx.run(query, params)
    record = result.single()
except TransientError as e:
    # Temporary issue - safe to retry
    logger.warning("transient_error",
                  error=str(e),
                  query_preview=query[:100],
                  retry_recommended=True)
    raise  # Let saga retry
except ConstraintError as e:
    # Data integrity issue - likely duplicate
    logger.warning("constraint_violation",
                  error=str(e),
                  query_preview=query[:100])
    # May want to handle specifically vs re-raise
    raise
except DatabaseError as e:
    # Database-level error
    logger.error("database_error",
                error=str(e),
                query_preview=query[:100])
    raise
except ServiceUnavailable as e:
    # Connection lost
    logger.error("neo4j_unavailable",
                error=str(e))
    raise
except Exception as e:
    # Unexpected error - log with full context
    logger.error("unexpected_error",
                error=str(e),
                query_preview=query[:100],
                exc_info=True)
    raise
```

---

### Fix #15: Config Hardcoded

**Severity**: HIGH
**Location**: Multiple files
**Effort**: 1 hour

#### Add to `config.yaml`

```yaml
references:
  enabled: false  # Disabled by default

  extraction:
    max_text_length: 8192
    window_overlap: 512
    confidence_scores:
      hyperlink: 0.95
      see_also: 0.85
      related: 0.80
      refer_to: 0.70

  resolution:
    fuzzy_penalty: 0.25
    batch_size: 100
    min_hint_length: 3
    use_fulltext_index: true

  query:
    enable_cross_doc_signals: true
    cross_doc_weight_ratio: 0.3
    max_referencing_docs: 3
```

#### Usage in Code

```python
# In references.py
MAX_TEXT_LENGTH_FOR_REGEX = config.references.extraction.max_text_length
CONFIDENCE_SCORES = config.references.extraction.confidence_scores

# In atomic.py
FUZZY_RESOLUTION_PENALTY = config.references.resolution.fuzzy_penalty
BATCH_SIZE = config.references.resolution.batch_size

# In hybrid_retrieval.py
CROSS_DOC_WEIGHT_RATIO = config.references.query.cross_doc_weight_ratio
```

---

## MEDIUM Issues (Fixes 16-22)

### Fix #16: Dual Labels Confuse Queries

**Location**: `atomic.py:1829`

```cypher
-- Before: Ghost has both labels
MERGE (ghost:Document:GhostDocument {id: ref.ghost_id})

-- After: Only GhostDocument label
MERGE (ghost:GhostDocument {id: ref.ghost_id})
```

---

### Fix #17: Source Allows Document

**Location**: `atomic.py:1801-1802`

```python
# Before
WHERE src:Chunk OR src:Document

# After - spec says Chunk-only source
WHERE src:Chunk
```

---

### Fix #18: Locale Mismatch

**Location**: `atomic.py:1729`

```python
# Use casefold() which is locale-independent
# Python side:
normalized_title = title.casefold()

# Cypher side - send casefolded version:
WHERE toLower(d.title) = $title_casefolded
```

---

### Fix #19: Regex Groups Fragile

**Location**: `references.py:110-124`

```python
# Use named groups for clarity
"see_also": re.compile(
    r"see\s+(?:also)?:?\s*\[(?P<md_link>[^\]]+)\]\([^)]+\)|"
    r"see\s+(?:also)?:?\s+(?P<plain_text>[A-Z][^\n\.\,]+?)(?:\s*[-â€“â€”]|$|\n|\.)",
    re.MULTILINE | re.IGNORECASE,
),

# Access via name
target = match.group("md_link") or match.group("plain_text")
```

---

### Fix #20: Unsanitized Logs

**Location**: `atomic.py:1899`

```python
def safe_log_value(value: str, max_length: int = 200) -> str:
    """Sanitize a value for safe logging."""
    if not value:
        return ""
    # Remove control characters
    sanitized = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', value)
    # Truncate
    if len(sanitized) > max_length:
        sanitized = sanitized[:max_length] + "..."
    return sanitized

# Usage
logger.info("reference_created",
            target_hint=safe_log_value(ref.target_hint))
```

---

### Fix #21: Fuzzy Penalty Fixed

**Location**: `atomic.py:1776`

```python
# Move to config (see Fix #15)
FUZZY_RESOLUTION_PENALTY = config.references.resolution.fuzzy_penalty
```

---

### Fix #22: No Query Feature Flag

**Location**: `hybrid_retrieval.py:2073`

```python
def _compute_cross_doc_signals(self, ...):
    # Check feature flag
    if not self.config.references.query.enable_cross_doc_signals:
        return {}
    # ... rest of method ...
```

---

## LOW Issues (Fixes 23-28)

### Fix #23: Dict Order Implicit

```python
# Document the dependency or use explicit list
REFERENCE_PATTERNS = [
    ("hyperlink", re.compile(...)),  # Priority 1
    ("see_also", re.compile(...)),   # Priority 2
    ("related", re.compile(...)),    # Priority 3
    ("refer_to", re.compile(...)),   # Priority 4
]
```

### Fix #24: Stale Schema Provider

```cypher
-- Update in schema file
sv.embedding_provider = 'bge-m3',
sv.embedding_model = 'BAAI/bge-m3',
```

### Fix #25: Magic Numbers

```python
# Add constants with docstrings
MAX_TEXT_LENGTH_FOR_REGEX = 8192
"""Maximum text length for regex matching. Prevents ReDoS."""

FUZZY_RESOLUTION_PENALTY = 0.25
"""Confidence penalty for fuzzy-matched references."""
```

### Fix #26: Metric Namespace Collision

```python
# Prefix all new metrics
references_created_total = Counter('references_created_total', ...)
references_ghost_created_total = Counter('references_ghost_created_total', ...)
```

### Fix #27: Entity Extractor Unnecessary

```python
# Short-circuit when cross-doc signals sufficient
if cross_doc_signals and len(cross_doc_signals) >= len(candidate_ids) * 0.5:
    logger.debug("skipping_entity_extraction",
                reason="sufficient_cross_doc_signals")
    # Use cross-doc only reranking
    return self._apply_cross_doc_only_rerank(...)
```

### Fix #28: No E2E Integration Test

```python
# tests/integration/test_references_e2e.py
def test_cross_doc_references_boost_retrieval():
    """Verify REFERENCES edges actually boost retrieval scores."""
    # 1. Ingest doc_a with hyperlink to doc_b
    ingest_document("tests/fixtures/doc_with_references_a.md")
    ingest_document("tests/fixtures/doc_with_references_b.md")

    # 2. Query for content in doc_b
    results = retrieve("tiered storage configuration", top_k=10)

    # 3. Verify doc_b appears with cross_doc_signal > 0
    doc_b_results = [r for r in results if "doc_with_references_b" in r.document_id]
    assert len(doc_b_results) > 0, "doc_b should appear in results"

    # 4. Verify cross-doc boost was applied
    # (requires metrics or debug output from retriever)
```

---

## Implementation Phases

### Phase A: Unblock Feature (Issues 1-8)
**Timeline**: ~2-3 days
**Goal**: Make REFERENCES actually work

| Order | Issue | Effort |
|:-----:|-------|:------:|
| 1 | Fix query traversal pattern | 2h |
| 2 | Fix ghost ID collision | 1h |
| 3 | Switch to fulltext index | 2h |
| 4-5 | Fix lock race conditions | 3h |
| 6 | Add batch chunking | 2h |
| 7 | Harden regex patterns | 2h |
| 8 | Add feature flag | 1h |

### Phase B: Performance & Stability (Issues 9-15)
**Timeline**: ~1-2 days
**Goal**: Production-ready performance

### Phase C: Correctness & Config (Issues 16-22)
**Timeline**: ~1 day
**Goal**: Clean up edge cases

### Phase D: Polish (Issues 23-28)
**Timeline**: ~0.5 days
**Goal**: Documentation and tests

---

## Model Confidence & Agreement

| Model | Stance | Confidence | Key Contribution |
|-------|--------|:----------:|------------------|
| o3 | FOR | 7/10 | Comprehensive ranked table |
| gpt-5.1-codex | AGAINST | 6/10 | Precise line numbers |
| gemini-3-pro-preview | NEUTRAL | 10/10 | Clear technical analysis |

---

## Appendix: Test Fixtures

The test fixtures in `tests/fixtures/` can be used to verify the fixes:

- `doc_with_references_a.md` - Contains hyperlinks to other docs
- `doc_with_references_b.md` - Target document for reference resolution
- `doc_with_references_c.md` - Additional test case
- `doc_with_references_d.md` - Edge case testing

---

*Generated by multi-model consensus analysis*
*Models: o3, gpt-5.1-codex, gemini-3-pro-preview*
*Date: 2025-11-30*
