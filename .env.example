# Implements Phase 1, Task 1.1 (Docker environment setup)
# See: /docs/spec.md ยง6 (Security)
# Copy this to .env and fill in actual values

# Environment
ENV=development

# Optional: Override default config file path
# CONFIG_PATH=./config/custom.yaml

# ============================================================================
# Tailscale Configuration (for MagicDNS access to external services)
# ============================================================================
# Generate an auth key at: https://login.tailscale.com/admin/settings/keys
# - Use a reusable key for development
# - Use an ephemeral key for CI/CD
# - Optionally add ?ephemeral=false to prevent node removal on restart
TS_AUTHKEY=tskey-auth-your-key-here

# MCP Server
MCP_PORT=8000
LOG_LEVEL=INFO

# Neo4j Configuration
NEO4J_USER=neo4j
NEO4J_PASSWORD=change-me-in-production
NEO4J_HEAP_INITIAL=512m
NEO4J_HEAP_MAX=1G
NEO4J_PAGECACHE=512m

# Redis Configuration
REDIS_PASSWORD=change-me-in-production
REDIS_MAXMEMORY=256mb

# Qdrant Configuration
QDRANT_LOG_LEVEL=INFO

# JWT Authentication
JWT_SECRET=change-me-to-a-long-random-string-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRY_MINUTES=60

# OpenTelemetry
# New Relic OTLP ingest (US)
NEW_RELIC_LICENSE_KEY=your-new-relic-license-key-here
OTEL_EXPORTER_OTLP_ENDPOINT=https://otlp.nr-data.net
OTEL_EXPORTER_OTLP_HEADERS=api-key=your-new-relic-license-key-here
OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf
OTEL_LOGS_EXPORTER=otlp
OTEL_TRACES_EXPORTER=otlp

# Rate Limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST_SIZE=10

# Embedding Configuration (referenced in config/development.yaml)
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_DIMS=384

# Phase 7C: Provider Configuration
# Embedding selection is controlled by the 'plan' section in config/embedding_profiles.yaml.
# Default: Arctic (dense) + BGE-M3 (sparse + ColBERT)
# The plan determines which profiles are used for each embedding role:
#   dense: snowflake_arctic_v2l  -> Snowflake Arctic (dense only)
#   sparse: bge_m3               -> BGE-M3 (sparse vectors)
#   colbert: bge_m3              -> BGE-M3 (ColBERT multi-vectors)
#
# Legacy single-profile mode (discouraged, use plan instead):
# EMBEDDINGS_PROFILE=snowflake_arctic_v2l
# EMBEDDINGS_PROVIDER=snowflake-arctic-service
# EMBEDDINGS_MODEL=Snowflake/snowflake-arctic-embed-l-v2.0
EMBEDDINGS_DIM=1024
EMBEDDINGS_TASK=retrieval.passage
# Profile safety + namespacing (set EMBEDDING_NAMESPACE_MODE to 'profile' to namespace collections/indexes)
EMBEDDING_STRICT_MODE=true
EMBEDDING_NAMESPACE_MODE=profile

# Reranking provider selection (bge-reranker-service | jina-ai | noop)
RERANK_PROVIDER=bge-reranker-service
RERANK_MODEL=Qwen/Qwen3-Reranker-0.6B
RERANKER_TOKENIZER_ID=Qwen/Qwen3-Reranker-0.6B
# Qwen3 reranker base URL (when using bge-reranker-service wrapper)
RERANKER_BASE_URL=http://host.docker.internal:9005
# Qwen3 reranker timeout
RERANKER_TIMEOUT_SECONDS=120
# RERANK_TOP_N=20

# Jina AI API Key (required when using jina-ai provider)
JINA_API_KEY=your-jina-api-key-here

# BGE-M3 service configuration (sparse + ColBERT embeddings)
# Used for: lexical matching, ColBERT late-interaction
BGE_M3_API_URL=http://127.0.0.1:9000
# Path to the canonical embedding client implementation (read/run access only)
BGE_M3_CLIENT_PATH=/Users/brennanconley/vibecode/bge-m3-custom/src

# Snowflake Arctic embedding service (dense embeddings + Chonkie chunking)
# Used for: primary dense embeddings, semantic chunk boundary detection
# This is the default dense embedder when using snowflake_arctic_v2l profile
CHONKIE_EMBEDDINGS_BASE_URL=http://127.0.0.1:9010/v1
CHONKIE_EMBEDDINGS_MODEL=snowflake-arctic-embed-l-v2.0
CHONKIE_EMBEDDINGS_DIM=1024
CHONKIE_EMBEDDINGS_TIMEOUT_SECONDS=60
# Optional: API key if service requires authentication
# CHONKIE_EMBEDDINGS_API_KEY=

# Guard-Split Chunking Architecture (BGE-M3 model limits)
# These prevent data loss by splitting oversized sections before embedding
BGE_M3_MAX_INPUT_TOKENS=8192      # Hard model limit per text
BGE_M3_SAFE_INPUT_TOKENS=8000     # Safe limit with margin
BGE_M3_GUARD_OVERLAP_TOKENS=200   # Overlap when guard-splitting
BGE_M3_OVERSIZE_POLICY=raise      # Policy: raise (fail-fast), truncate, split_and_pool
BGE_M3_MAX_BATCH_TOKENS=7500      # Max total tokens across all texts in one HTTP batch

# Budget Controls (Phase 7C)
DAILY_BUDGET_USD=50
MONTHLY_BUDGET_USD=100
BUDGET_ALERT_THRESHOLD=0.8

# Feature Flags (Phase 7C)
DUAL_WRITE_1024D=false
SESSION_TRACKING_ENABLED=false
ENTITY_FOCUS_BIAS=false

# Phase 6: Auto-Ingestion Service
INGESTION_SERVICE_HOST=0.0.0.0
INGESTION_SERVICE_PORT=9108

# Ingestion watch paths (configured in config/development.yaml)
# INGEST_WATCH_PATH=./ingest/watch

# Back-pressure thresholds (can override config values)
# INGEST_NEO4J_CPU_THRESHOLD=0.8
# INGEST_QDRANT_P95_THRESHOLD_MS=200.0
