diff --git a/tests/p4_t1_complex_patterns_test.py b/tests/p4_t1_complex_patterns_test.py
--- a/tests/p4_t1_complex_patterns_test.py
+++ b/tests/p4_t1_complex_patterns_test.py
@@ -3,20 +3,18 @@
 import pytest
 from neo4j import GraphDatabase

-# --- Minimal fallback fixtures (used only if global conftest fixtures aren't present) ---
-def _mk_driver():
+@pytest.fixture(scope="module")
+def neo4j_driver():
+    """Always provide a synchronous Neo4j driver and yield it properly."""
     uri = os.getenv("NEO4J_URI", "bolt://localhost:7687")
     user = os.getenv("NEO4J_USER", "neo4j")
-    pwd = os.getenv("NEO4J_PASSWORD", "test")
-    return GraphDatabase.driver(uri, auth=(user, pwd))
-@pytest.fixture(scope="module")
-def neo4j_driver(request):
-    if "neo4j_driver" in request.fixturenames:
-        return request.getfixturevalue("neo4j_driver")
-    drv = _mk_driver()
-    yield drv
-    drv.close()
-# -----------------------------------------------------------------------------------------
+    pwd  = os.getenv("NEO4J_PASSWORD", "test")
+    drv = GraphDatabase.driver(uri, auth=(user, pwd))
+    try:
+        yield drv
+    finally:
+        drv.close()
+

 TEST_NS = f"p4_{uuid.uuid4().hex[:8]}"

diff --git a/tests/p4_t2_optimizer_test.py b/tests/p4_t2_optimizer_test.py
--- a/tests/p4_t2_optimizer_test.py
+++ b/tests/p4_t2_optimizer_test.py
@@ -2,19 +2,18 @@
 import os, pytest
 from neo4j import GraphDatabase

-def _mk_driver():
+@pytest.fixture(scope="module")
+def neo4j_driver():
+    """Always provide a synchronous Neo4j driver and yield it properly."""
     uri = os.getenv("NEO4J_URI", "bolt://localhost:7687")
     user = os.getenv("NEO4J_USER", "neo4j")
-    pwd = os.getenv("NEO4J_PASSWORD", "test")
-    return GraphDatabase.driver(uri, auth=(user, pwd))
+    pwd  = os.getenv("NEO4J_PASSWORD", "test")
+    drv = GraphDatabase.driver(uri, auth=(user, pwd))
+    try:
+        yield drv
+    finally:
+        drv.close()

-@pytest.fixture(scope="module")
-def neo4j_driver(request):
-    if "neo4j_driver" in request.fixturenames:
-        return request.getfixturevalue("neo4j_driver")
-    drv = _mk_driver()
-    yield drv
-    drv.close()

 def _flatten_plan(plan):
     ops = []
diff --git a/tests/p4_t3_cache_perf_test.py b/tests/p4_t3_cache_perf_test.py
--- a/tests/p4_t3_cache_perf_test.py
+++ b/tests/p4_t3_cache_perf_test.py
@@ -4,15 +4,13 @@

 MCP_URL = os.getenv("MCP_BASE_URL", "http://localhost:3000/mcp")

-def _mk_redis():
+
+
+
+@pytest.fixture(scope="module", name="redis_sync")
+def _redis_sync():
+    """Return a synchronous Redis client regardless of any async fixture elsewhere."""
     return Redis.from_url(os.getenv("CACHE_REDIS_URI", "redis://localhost:6379"), decode_responses=True)
-
-@pytest.fixture(scope="module")
-def redis_client(request):
-    if "redis_client" in request.fixturenames:
-        return request.getfixturevalue("redis_client")
-    return _mk_redis()
-
 def _call_tool(name: str, args: dict):
     payload = {"method": "tools/call", "params": {"name": name, "arguments": args}, "id": str(uuid.uuid4())}
     r = requests.post(f"{MCP_URL}", json=payload, timeout=30)
@@ -20,7 +18,7 @@
     return r.json()

 @pytest.mark.order(6)
-def test_cold_to_warm_latency_improves_and_cache_key_exists(redis_client):
+def test_cold_to_warm_latency_improves_and_cache_key_exists(redis_sync):
     # Tool name should match your serverâ€™s registry (adjust if different)
     tool = os.getenv("P4_CACHE_TEST_TOOL", "search_documentation")
     args = {"query": "fsync configuration", "limit": 5}
@@ -29,7 +27,7 @@
     cache_key = f"tool:{tool}:{json.dumps(args, sort_keys=True)}"

     # Ensure clean slate
-    redis_client.delete(cache_key)
+    redis_sync.delete(cache_key)

     t0 = time.time()
     _ = _call_tool(tool, args)   # cold
@@ -43,11 +41,11 @@

     assert warm_ms < cold_ms * 0.6, f"Warm call ({warm_ms:.1f}ms) not at least 40% faster than cold ({cold_ms:.1f}ms)."
     # Key must exist in Redis after first call
-    assert redis_client.get(cache_key) is not None, f"Expected Redis key {cache_key} to exist."
+    assert redis_sync.get(cache_key) is not None, f"Expected Redis key {cache_key} to exist."

 @pytest.mark.xfail(reason="Cache invalidation via versioning not yet implemented")
 @pytest.mark.order(7)
-def test_cache_invalidation_after_graph_update(redis_client):
+def test_cache_invalidation_after_graph_update(redis_sync):
     """
     Kickoff guardrail: once you implement cache versioning/bust on writes or epoch keys,
     this should pass automatically.
@@ -57,9 +55,9 @@
     cache_key = f"tool:{tool}:{json.dumps(args, sort_keys=True)}"

     # Simulate an update: bump a cache epoch key the server should include in user cache keys.
-    # e.g., redis_client.incr("cache:epoch:query")
+    # e.g., redis_sync.incr("cache:epoch:query")
     # For kickoff we assert the server deletes old key or uses a new versioned key.
-    old = redis_client.get(cache_key)
+    old = redis_sync.get(cache_key)
     # Expectation: after an update operation (ingestion or write), the previous key is gone or a new key is used.
     # Implementers: wire this to your write path or reconciliation logic.
     assert old is None, "After update, old cache key should be invalidated or superseded."
