

---

## üìÅ Repository layout (top‚Äëlevel)

```
/docs/
  spec.md                       # v2 Application Specification (canonical)
  implementation-plan.md        # v2 Implementation Plan (canonical)
  expert-coder-guidance.md      # v2 Expert Coder Guidance (canonical)
  pseudocode-reference.md       # v2 Pseudocode Reference (canonical)

/src/                           # app source (scaffolds listed later)
/scripts/                       # scripts (schema, ci, ops, test helpers)
/tests/                         # phase- & task-aligned tests (NO MOCKS)
/reports/                       # test artifacts generated by CI and local runs
  phase-1/
  phase-2/
  phase-3/
  phase-4/
  phase-5/

.github/
  pull_request_template.md
  workflows/ci.yml

Makefile
docker-compose.yml
config/*.yaml
```

---

# 1) `/docs/spec.md` ‚Äî **WekaDocs GraphRAG MCP ‚Äî Application Specification (v2, canonical)**

**Status:** Canonical v2. Supersedes all prior versions.

### 0) Purpose & scope

WekaDocs GraphRAG MCP is a secure, explainable documentation intelligence layer that lets LLMs query a **Neo4j** knowledge graph enriched with **vector search**. It ingests Markdown/HTML/Notion docs into a **provenance‚Äëfirst** graph (`Document ‚Üí Section ‚Üí Entities`) and answers complex technical questions via **hybrid retrieval** (semantic + graph), **safe, parameterized Cypher** (templates‚Äëfirst + validator + `EXPLAIN` plan checks), and **structured responses** (Markdown + JSON with evidence and confidence).

---

## 1) Goals & non‚Äëgoals

**Goals**

* Evidence‚Äëbacked answers with citations down to **Section** granularity.
* Deterministic, idempotent ingestion with incremental updates and rollback.
* P95 latency < **500ms** for common queries (warmed caches).
* Defense‚Äëin‚Äëdepth: injection resistance, plan‚Äëgated Cypher, rate‚Äëlimits.

**Non‚Äëgoals**

* General web search; document editing UX; multi‚Äëtenant isolation beyond single org.

---

## 2) Architecture (high level)

```
LLM Client (MCP) ‚Üí FastAPI MCP Server
  ‚îú‚îÄ Tools Registry (Search / Traverse / Compare / Troubleshoot / Explain)
  ‚îú‚îÄ Query Planner (Templates-first; optional LLM proposal)
  ‚îú‚îÄ Cypher Validator (regex guard + parameterization + EXPLAIN plan gates)
  ‚îú‚îÄ Hybrid Retrieval (Vector + Graph; ranker)
  ‚îú‚îÄ Response Builder (Markdown + JSON + Evidence + Confidence)
  ‚îú‚îÄ Auth + Rate Limits + Audit
  ‚îú‚îÄ Cache (L1 in-proc, L2 Redis)
  ‚îî‚îÄ OpenTelemetry Tracing + Metrics

Ingestion Worker
  ‚îú‚îÄ Parsers (Markdown/HTML/Notion ‚Üí Document/Section)
  ‚îú‚îÄ Entity Extractors (Command/Configuration/Procedure/Error/Concept/Example/Step/Parameter)
  ‚îú‚îÄ Graph Builder (MERGE by deterministic IDs; provenance on all edges)
  ‚îú‚îÄ Embeddings (configurable model/dims)
  ‚îú‚îÄ Vector Upsert (Primary store: Qdrant OR Neo4j vectors; dual-write optional)
  ‚îî‚îÄ Reconciliation & Drift Repair

Storage: Neo4j 5.x (+ APOC/GDS), Qdrant (optional primary), Redis
```

---

## 3) Data model (v2, provenance‚Äëfirst)

### 3.1 Node labels

* **Document** `{id, source_uri, source_type, title, version, checksum, last_edited}`
* **Section** `{id, document_id, level, title, anchor, order, text, tokens, checksum, vector_embedding?, embedding_version?}`
* **Domain entities:** `Command, Configuration, Procedure, Error, Concept, Example, Step, Parameter, Component`
  *(All domain nodes share `{id, name|title|term..., description?, category?, introduced_in?, deprecated_in?, updated_at, vector_embedding?, embedding_version?}`)*

### 3.2 Relationships (all with provenance)

* `(Document)-[:HAS_SECTION {order}]->(Section)`
* `(Section)-[:MENTIONS {confidence, start, end, source_section_id}]->(Entity)`
* Derived edges (each has `derived_from_section_id`, `confidence`):
  `REQUIRES, AFFECTS, RESOLVES, CONTAINS_STEP{order}, EXECUTES, RELATED_TO, HAS_PARAMETER, DEPENDS_ON, EQUIVALENT_TO`

### 3.3 IDs, versions, consistency

* Deterministic IDs (SHA‚Äë256) from normalized tuples (`source_uri`, `anchor`, `text`, etc.).
* `schema_version` singleton; caches & vectors **prefixed** with `{schema_version}:{embedding_version}`.
* Embedding config is dynamic (`model_name`, `dims`, `similarity`, `multilingual`, `version`).

---

## 4) Retrieval & query planning

* **Templates‚Äëfirst** NL‚ÜíCypher; LLM proposal only as fallback; **never execute raw**.
* **Parameterization only**; reject literal user inputs in `WHERE`.
* **Validator**: regex guardrails + **`EXPLAIN` plan inspection** to cap label scans, expansions, depth; enforce **timeouts** and **LIMITs** early.

---

## 5) Responses & explainability

* Dual output:

  * **Markdown** for humans.
  * **JSON** `{answer, evidence[{section_id, path}], confidence, diagnostics{ranking_features}}`.
* ‚Äú**Why these results?**‚Äù surface ranking features.
* **Disambiguation** card for homonyms.

---

## 6) Security

JWT auth; per‚Äëclient rate limits (Redis token bucket); audit logging (query hash, params hash, plan stats); TLS/mTLS; secrets via K8s/Docker secrets or Vault; parameterized Cypher only.

---

## 7) Observability & SLOs

OpenTelemetry tracing (FastAPI, Neo4j driver, vector calls). Metrics: P50/P95/P99 latency, cache hit/miss, slow Cypher, vector latency, queue lag, reconciliation drift.
**Targets:** P50<200ms, P95<500ms, P99<2s; availability 99.9%.

---

## 8) Ingestion pipeline

1. Parse ‚Üí `Document/Section`; preserve headings, anchors, code, tables; compute checksums.
2. Chunking: **Section** is primary chunk; split only when very long; use **title trail**.
3. Extract entities; write `MENTIONS` with spans + confidence.
4. MERGE graph (deterministic IDs) in batches with timeouts.
5. Embeddings (configurable) ‚Üí **primary vector store** (Qdrant *or* Neo4j); **dual‚Äëwrite** optional behind a flag.
6. Nightly reconciliation (graph vs vector) + drift repair.

---

## 9) Interfaces

**MCP tools:** `search_documentation`, `traverse_relationships`, `compare_systems`, `troubleshoot_error`, `explain_architecture`, plus utilities `disambiguate`, `explain_ranking`, `show_path`, `list_configs_affecting`.
**HTTP:** `/mcp`, `/health`, `/ready`, `/metrics` (auth & rate‚Äëlimited where appropriate).

---

## 10) Phases & tasks (alignment key)

* **Phase 1 ‚Äì Core Infrastructure**: **1.1** Docker env ¬∑ **1.2** MCP server ¬∑ **1.3** DB schema ¬∑ **1.4** Security
* **Phase 2 ‚Äì Query Processing Engine**: **2.1** NL‚ÜíCypher ¬∑ **2.2** Validator ¬∑ **2.3** Hybrid search ¬∑ **2.4** Response gen
* **Phase 3 ‚Äì Ingestion Pipeline**: **3.1** Parsers ¬∑ **3.2** Extraction ¬∑ **3.3** Graph build ¬∑ **3.4** Incremental
* **Phase 4 ‚Äì Advanced Query Features**: **4.1** Complex templates ¬∑ **4.2** Optimization ¬∑ **4.3** Caching ¬∑ **4.4** Learning
* **Phase 5 ‚Äì Integration & Deployment**: **5.1** External systems ¬∑ **5.2** Monitoring ¬∑ **5.3** Testing framework ¬∑ **5.4** Prod deploy

---

## 11) Success criteria & risks

* Evidence & confidence on every answer.
* Validator rejects unsafe plans; caches versioned; drift <0.5% daily.
* Chaos tests for vector outage, Neo4j backpressure, cache poisoning.
  Key risks: query complexity explosion, drift, performance regressions ‚Äî mitigated via guardrails, reconciliation, dashboards & alerts.

---

## 12) Phase gates (no‚Äëmocks testing required)

Each phase must **produce and attach** machine‚Äëreadable test results under `/reports/phase-N/summary.json` and JUnit XML under `/reports/phase-N/junit.xml`. **No mocks anywhere.** Gates block promotion until all criteria pass:

* **Gate P1 ‚Üí P2:** infra green; auth/rate‚Äëlimit enforced; schema created; tracing on; **tests** for health, auth, rate limiting, schema idempotency all pass; artifacts saved.
* **Gate P2 ‚Üí P3:** validator blocks attacks; hybrid search P95 < 500ms (warmed); responses include evidence & confidence; artifacts saved.
* **Gate P3 ‚Üí P4:** ingestion deterministic; incremental update limited to changed sections; reconciliation drift < 0.5%; artifacts saved.
* **Gate P4 ‚Üí P5:** advanced templates pass guardrails; cache hit > 80% steady; artifacts saved.
* **Gate P5 ‚Üí Launch:** full test matrix green; monitoring/alerts live; DR drill passes; artifacts saved.

---

# 2) `/docs/implementation-plan.md` ‚Äî **Implementation Plan (v2, canonical)**

**Status:** Canonical v2. Phase/task IDs match spec and guidance exactly.
**Rule:** Before exiting a phase, produce **no‚Äëmocks** test results in `/reports/phase-N/` and pass the **Phase Gate**.

### Conventions

* **Owner**, **Deps**, **Deliverables**, **DoD** (definition of done), **Tests (NO MOCKS)**, **Artifacts**, **Gate**.
* All commands run from repo root unless noted.
* Configurable via `config/*.yaml`.

---

## Phase 1 ‚Äì Core Infrastructure

### **Task 1.1 ‚Äì Docker environment setup**

**Owner:** Platform | **Deps:** ‚Äî
**Steps:** Compose services (`mcp-server`, `neo4j`, `qdrant` optional, `redis`, `ingestion-worker`, optional `nginx`); CPU/mem limits; healthchecks with realistic timeouts; volumes; secrets via Docker/K8s secrets; `weka-net` network.
**Deliverables:** `docker-compose.yml`, `.env.example`, `docker/*` Dockerfiles.
**DoD:** `docker compose up -d` ‚Üí all healthy; restart preserves data; secrets not visible via `docker inspect`.
**Tests (NO MOCKS):**

* Spin stack; hit `/health`, `/ready`; Redis `PING`; Qdrant `/health` (if enabled); Bolt connect.
* Restart containers; validate data persistence.
  **Artifacts:** `/reports/phase-1/junit.xml`, `/reports/phase-1/summary.json` (schema below).
  **Gate:** P1 infra green per tests; artifacts present.

---

### **Task 1.2 ‚Äì MCP server foundation**

**Owner:** Backend | **Deps:** 1.1
**Steps:** FastAPI app; MCP endpoints (`initialize`, `tools/list`, `tools/call`, `completion`); connection pools; graceful shutdown; OTel middleware; structured logs with correlation IDs; `/metrics`.
**Deliverables:** `src/mcp_server/main.py`, `src/mcp_server/tools/*`, OTel config.
**DoD:** `tools/list` shows tools; `tools/call` executes; traces appear; metrics scrape OK.
**Tests (NO MOCKS):** Call endpoints against running stack; assert JSON shape, tool outputs; verify traces & metrics via scrape.
**Artifacts:** `/reports/phase-1/*`.
**Gate:** Included in P1 gate.

---

### **Task 1.3 ‚Äì Database schema initialization**

**Owner:** Graph Eng | **Deps:** 1.1
**Steps:** Create **Document/Section**; constraints/indexes; vector indexes with **config dims/similarity**; `schema_version` node.
**Deliverables:** `scripts/neo4j/create_schema.cypher`, `src/shared/schema.py`.
**DoD:** `CALL db.indexes()` shows property + vector indexes; re‚Äërun scripts idempotent.
**Tests (NO MOCKS):** Apply schema to live Neo4j; re‚Äëapply; query `db.indexes`; attempt writes using expected labels and properties.
**Artifacts:** `/reports/phase-1/*`.
**Gate:** Included in P1 gate.

---

### **Task 1.4 ‚Äì Security layer**

**Owner:** Platform+Backend | **Deps:** 1.2
**Steps:** JWT auth; Redis token bucket; audit log store; parameterized Cypher only; validator interface ready for P2.
**Deliverables:** auth middleware; rate limiter; audit sink.
**DoD:** Auth required on `/mcp`; rate limits trigger under load; audit entries recorded with correlation IDs.
**Tests (NO MOCKS):** Burst requests to trigger 429; invalid JWT denied; audit log entries verified via DB or log scraping.
**Artifacts:** `/reports/phase-1/*`.
**Gate:** Included in P1 gate.

---

## Phase 2 ‚Äì Query Processing Engine

### **Task 2.1 ‚Äì NL ‚Üí Cypher translation**

**Owner:** Retrieval | **Deps:** 1.2, 1.3
**Steps:** Intent classifier; entity linker; **template library** for known intents; optional LLM‚Äëproposal path; normalization & parameterization; hard caps injected early.
**Deliverables:** `src/query/planner.py`, `src/query/templates/*.cypher`.
**DoD:** ‚â•90% user stories resolved via templates; fallback proposals pass validator.
**Tests (NO MOCKS):** For a corpus of real prompts, ensure produced queries are parameterized, limited, depth‚Äëbounded; run against live Neo4j test data; verify outputs.
**Artifacts:** `/reports/phase-2/*`.
**Gate:** Included in P2 gate.

---

### **Task 2.2 ‚Äì Cypher validation system**

**Owner:** Graph Eng | **Deps:** 2.1
**Steps:** Regex guardrails; fix variable‚Äëlength pattern; parameter enforcement; run **`EXPLAIN`**; reject plans exceeding thresholds (label scans, expansions, depth); enforce server timeouts.
**Deliverables:** `src/mcp_server/validation.py`.
**DoD:** Injection/expensive patterns blocked; false positives < 5%.
**Tests (NO MOCKS):** Execute malicious & deep queries against live DB; assert 4xx/blocked; verify legitimate templates pass and return results.
**Artifacts:** `/reports/phase-2/*`.
**Gate:** Included in P2 gate.

---

### **Task 2.3 ‚Äì Hybrid search**

**Owner:** Retrieval | **Deps:** 1.3, 2.2
**Steps:** Choose **primary vector store** (`qdrant | neo4j`); implement vector top‚ÄëK (Sections + optional Entities) ‚Üí controlled 1‚Äì2 hop expansion ‚Üí optional connecting paths; ranker blends semantic, graph, recency.
**Deliverables:** `src/query/hybrid_search.py`, `src/query/ranking.py`.
**DoD:** P95 < 500ms at K=20 (warmed); deterministic ranking ties.
**Tests (NO MOCKS):** Seed real vectors; run queries under Locust/k6; capture latency percentiles; verify expansions bounded by config.
**Artifacts:** `/reports/phase-2/*`.
**Gate:** Included in P2 gate.

---

### **Task 2.4 ‚Äì Response generation**

**Owner:** Backend | **Deps:** 2.3
**Steps:** Build human Markdown + JSON (`answer, evidence[{section_id, path}], confidence, diagnostics`); ‚ÄúWhy these results?‚Äù reveals ranking features; disambiguation for homonyms.
**Deliverables:** `src/query/response_builder.py`.
**DoD:** Answers include evidence & confidence; JSON schema validated.
**Tests (NO MOCKS):** E2E queries against live stack; assertions on JSON schema, evidence paths, confidence bounds.
**Artifacts:** `/reports/phase-2/*`.
**Gate:** Included in P2 gate.

---

## Phase 3 ‚Äì Ingestion Pipeline

### **Task 3.1 ‚Äì Multi‚Äëformat parser**

**Owner:** Ingestion | **Deps:** 1.3
**Steps:** Parse Markdown/HTML/Notion ‚Üí **Document/Section**; preserve anchors, code, tables; compute `section_checksum`, `section_id`; store token counts.
**Deliverables:** `src/ingestion/parsers/{markdown,html,notion}.py`.
**DoD:** Deterministic sections; rerun yields identical IDs.
**Tests (NO MOCKS):** Feed real docs; compare IDs/checksums across runs; ensure anchors preserved.
**Artifacts:** `/reports/phase-3/*`.
**Gate:** Included in P3 gate.

---

### **Task 3.2 ‚Äì Entity extraction**

**Owner:** Ingestion | **Deps:** 3.1
**Steps:** Pattern + light NLP to extract `Command/Configuration/Procedure/Error/Concept/Example/Step/Parameter`; write `MENTIONS` with spans + confidence (no heavy inference yet).
**Deliverables:** `src/ingestion/extract/*`.
**DoD:** >95% precision on commands/configs against a labeled sample.
**Tests (NO MOCKS):** Run against labeled real docs; compute precision/recall; store metrics file.
**Artifacts:** `/reports/phase-3/*`.
**Gate:** Included in P3 gate.

---

### **Task 3.3 ‚Äì Graph construction**

**Owner:** Graph Eng | **Deps:** 3.2
**Steps:** MERGE by deterministic IDs; set provenance & timestamps; batch with `apoc.periodic.iterate` and tx timeouts; compute embeddings; upsert to **primary vector store**; set `embedding_version`.
**Deliverables:** `src/ingestion/build_graph.py`.
**DoD:** Idempotent; re‚Äëingestion of unchanged docs results in no diffs.
**Tests (NO MOCKS):** Ingest same doc twice; assert node/edge counts stable; verify vector count parity with graph.
**Artifacts:** `/reports/phase-3/*`.
**Gate:** Included in P3 gate.

---

### **Task 3.4 ‚Äì Incremental update**

**Owner:** Ingestion | **Deps:** 3.3
**Steps:** Diff via `section_checksum`; stage `:Section_Staged`; atomic relabel swap; re‚Äëembed changed & adjacent only; nightly reconciliation & repair.
**Deliverables:** `src/ingestion/incremental.py`, `src/ingestion/reconcile.py`.
**DoD:** Small edits update O(changed sections); drift <0.5% overnight.
**Tests (NO MOCKS):** Edit one section; verify only minimal graph/vector delta; run reconciliation and confirm parity.
**Artifacts:** `/reports/phase-3/*`.
**Gate:** Included in P3 gate.

---

## Phase 4 ‚Äì Advanced Query Features

### **Task 4.1 ‚Äì Complex query templates**

**Owner:** Retrieval | **Deps:** 2.x
**Steps:** Pre‚Äëapproved templates: dependency chain, impact analysis, troubleshooting path, comparison, temporal ‚Äúas of version Y‚Äù; define input/output schemas & plan guardrails.
**Deliverables:** `src/query/templates/advanced/*.cypher`.
**DoD:** Templates execute within depth/time budgets; validated.
**Tests (NO MOCKS):** Execute each template on live graph; assert outputs, plan bounds, runtime.
**Artifacts:** `/reports/phase-4/*`.
**Gate:** Included in P4 gate.

---

### **Task 4.2 ‚Äì Query optimization**

**Owner:** Graph Eng | **Deps:** 4.1
**Steps:** Slow‚Äëquery analysis; index recommendations; query rewriting; compiled plan cache for hot templates.
**Deliverables:** `src/ops/optimizer.py`, dashboards.
**DoD:** Documented P95 improvement on hot paths.
**Tests (NO MOCKS):** Before/after benchmarks with Locust/k6; attach comparison CSV.
**Artifacts:** `/reports/phase-4/*`.
**Gate:** Included in P4 gate.

---

### **Task 4.3 ‚Äì Caching & performance**

**Owner:** Backend | **Deps:** 2.x
**Steps:** L1 in‚Äëproc + L2 Redis; cache keys prefixed with `{schema_version}:{embedding_version}`; daily warmers; optional materialization of expensive patterns.
**Deliverables:** `src/shared/cache.py`, warmers.
**DoD:** >80% hit rate steady; correctness under model/schema rotation.
**Tests (NO MOCKS):** Rotate embedding version; verify cache invalidation & correctness; measure hit rate over load.
**Artifacts:** `/reports/phase-4/*`.
**Gate:** Included in P4 gate.

---

### **Task 4.4 ‚Äì Learning & adaptation**

**Owner:** Retrieval | **Deps:** 2‚Äì4
**Steps:** Log query‚Üíresult‚Üífeedback; update ranking weights; propose new templates & indexes.
**Deliverables:** `src/learning/*`.
**DoD:** Relevance lift (NDCG) on held‚Äëout set.
**Tests (NO MOCKS):** Offline evaluation from real logs; attach metrics plots/CSV.
**Artifacts:** `/reports/phase-4/*`.
**Gate:** Included in P4 gate.

---

## Phase 5 ‚Äì Integration & Deployment

### **Task 5.1 ‚Äì External systems**

**Owner:** Platform | **Deps:** 3.x
**Steps:** Notion/GitHub/Confluence connectors; webhooks or polling; queue ingestion; circuit breakers; Slack notifications.
**Deliverables:** `src/connectors/*`, runbooks.
**DoD:** Steady ingestion under rate limits; degraded mode works.
**Tests (NO MOCKS):** Use demo workspaces/repos; ingest deltas end‚Äëto‚Äëend; throttle to trigger backoff.
**Artifacts:** `/reports/phase-5/*`.
**Gate:** Included in P5 gate.

---

### **Task 5.2 ‚Äì Monitoring & observability**

**Owner:** SRE | **Deps:** 1.2
**Steps:** Prometheus exporters; Grafana dashboards; OTel traces; alerts (P99, errors, drift, OOM).
**Deliverables:** `deploy/monitoring/*`, runbooks.
**DoD:** On‚Äëcall can diagnose slow/failed queries in <10 min.
**Tests (NO MOCKS):** Fire alerts via synthetic load; capture traces and screenshots.
**Artifacts:** `/reports/phase-5/*`.
**Gate:** Included in P5 gate.

---

### **Task 5.3 ‚Äì Testing framework**

**Owner:** QA | **Deps:** all
**Steps:** **No‚Äëmocks** unit/integration/E2E/perf/security/chaos; golden graph determinism; CI gates.
**Deliverables:** `tests/*`, CI workflow, chaos scenarios.
**DoD:** CI blocks on any determinism or evidence regression.
**Tests (NO MOCKS):** Entire matrix against live stack from compose; chaos: kill vector/slow Neo4j; verify degraded behavior.
**Artifacts:** `/reports/phase-5/*`.
**Gate:** Included in P5 gate.

---

### **Task 5.4 ‚Äì Production deployment**

**Owner:** Platform/SRE | **Deps:** 5.2, 5.3
**Steps:** Blue/green + canary; feature flags; backups; DR drills (RTO 1h, RPO 15m).
**Deliverables:** K8s manifests/Helm, CI/CD, runbooks.
**DoD:** Canary 5% for 1h, auto‚Äërollback on SLI breach; DR drill passes.
**Tests (NO MOCKS):** Stage‚ÜíProd canary; forced rollback; documented DR restore.
**Artifacts:** `/reports/phase-5/*`.
**Gate:** Launch.

---

### Test artifact schema (applies to all phases)

`/reports/phase-N/summary.json`:

```json
{
  "phase": "N",
  "date_utc": "2025-10-12T00:00:00Z",
  "commit": "<git-sha>",
  "results": [
    {"task": "1.1", "name": "stack_healthy", "status": "pass", "duration_ms": 4123},
    {"task": "1.2", "name": "mcp_tools_list", "status": "pass", "duration_ms": 203}
  ],
  "metrics": {
    "latency_ms_p50": 120,
    "latency_ms_p95": 480,
    "cache_hit_rate": 0.83,
    "reconciliation_drift_pct": 0.2
  },
  "artifacts": [
    "junit.xml",
    "logs.tar.gz",
    "perf.csv"
  ]
}
```

`/reports/phase-N/junit.xml`: standard JUnit XML for CI.

---

# 3) `/docs/expert-coder-guidance.md` ‚Äî **Expert Coder Guidance (v2, canonical)**

**Status:** Canonical v2. Phase/task IDs align 1.1‚Üí5.4.

### Guidance pattern (applies to each task)

* **Do this:** concrete steps and priority order.
* **Pitfalls:** frequent errors and how to avoid them.
* **Definition of Done:** objective checks.
* **Acceptance checklist:** what the reviewer will verify.
* **Notes for performance & safety:** limits, timeouts, guardrails.

---

## Phase 1

**1.1 Docker env**

* **Do this:** parameterize service URLs; healthchecks; secrets via Docker/K8s; set Neo4j heap/pagecache once; volumes.
* **Pitfalls:** conflicting memory env vars; missing healthcheck timeouts.
* **DoD:** all services healthy; restart preserves data.
* **Checklist:** `docker ps`, health, persistence, logs rotation.

**1.2 MCP server**

* **Do this:** FastAPI, MCP endpoints, OTel, structured logs, connection pools, graceful shutdown.
* **Pitfalls:** not closing Bolt sessions; missing correlation IDs.
* **DoD:** tools list/call works; traces & metrics present.
* **Checklist:** curl endpoints; View traces in collector.

**1.3 Schema**

* **Do this:** add `Document/Section`; vector indexes from config; `schema_version` node.
* **Pitfalls:** hard‚Äëcoding vector dims; label/property drift.
* **DoD:** indexes exist; idempotent re‚Äëruns.
* **Checklist:** `CALL db.indexes()`; re-run script success.

**1.4 Security**

* **Do this:** JWT auth; Redis token bucket; parameterized Cypher; audit everything.
* **Pitfalls:** trusting literals; forgetting timeouts.
* **DoD:** blocked invalid JWT; 429 under burst; audit entries exist.
* **Checklist:** negative tests pass; audit log lines visible.

---

## Phase 2

**2.1 NL‚ÜíCypher**

* **Do this:** intent classifier; entity linker; **templates-first**; fallback LLM proposal; normalize & parameterize; inject limits early.
* **Pitfalls:** executing raw LLM output; missing LIMIT at right place.
* **DoD:** 90% via templates; fallback queries pass validator.
* **Checklist:** corpus run; parameter enforcement.

**2.2 Validator**

* **Do this:** correct `*min..max`; parameter enforcement; run `EXPLAIN`; cap scans/expansions/depth; enforce timeout; early LIMITs.
* **Pitfalls:** regex-only validation; appending LIMIT too late.
* **DoD:** malicious queries blocked; legitimate pass; FP <5%.
* **Checklist:** negative suite; plan stats checked.

**2.3 Hybrid search**

* **Do this:** choose vector SoT; top‚ÄëK Sections (optional Entities); 1‚Äì2 hop expansion; connecting paths; rank by semantic+graph+recency.
* **Pitfalls:** explosive expansions; missing dedupe.
* **DoD:** P95 < 500ms at K=20; bounded hops.
* **Checklist:** load test; top‚ÄëK correctness.

**2.4 Response**

* **Do this:** Markdown+JSON; evidence (Section, path); confidence estimate; ‚ÄúWhy these results?‚Äù; disambiguation.
* **Pitfalls:** missing evidence IDs; unbounded JSON size.
* **DoD:** schema‚Äëvalid JSON; confidence ‚àà [0,1].
* **Checklist:** E2E snapshots; schema validator.

---

## Phase 3

**3.1 Parser**

* **Do this:** retain anchors, code, tables; compute deterministic `section_id`; token counts.
* **Pitfalls:** losing anchors; non‚Äëdeterministic parsing.
* **DoD:** identical output across runs.
* **Checklist:** checksum comparison.

**3.2 Extraction**

* **Do this:** pattern+light NLP; `MENTIONS` with spans + confidence.
* **Pitfalls:** over‚Äëdedupe of near‚Äëaliases.
* **DoD:** >95% precision on commands/configs.
* **Checklist:** labeled evaluation; metrics report.

**3.3 Graph build**

* **Do this:** MERGE IDs; provenance on edges; batch writes; embeddings; vector upsert; set `embedding_version`.
* **Pitfalls:** non‚Äëidempotent merges; drift between graph and vectors.
* **DoD:** re‚Äëingestion diffs=0; vector parity.
* **Checklist:** counts stable; reconciliation parity.

**3.4 Incremental**

* **Do this:** staged labels; atomic swap; partial re‚Äëembed; nightly reconciliation + repair.
* **Pitfalls:** mass re‚Äëembeddings; label swap leaving orphans.
* **DoD:** O(changed sections) updates; drift <0.5%.
* **Checklist:** controlled delta; drift metric.

---

## Phase 4

**4.1 Complex templates**

* **Do this:** pre‚Äëapprove; input/output schemas; plan guardrails.
* **Pitfalls:** unbounded traversals.
* **DoD:** run within depth/time budgets.
* **Checklist:** plan inspection; result shape validated.

**4.2 Optimization**

* **Do this:** analyze slow queries; recommend indexes; rewrite templates; plan caching.
* **Pitfalls:** adding indexes that fight each other.
* **DoD:** measurable P95 improvement.
* **Checklist:** before/after perf CSV.

**4.3 Caching**

* **Do this:** L1+L2; version‚Äëprefixed keys; warmers; optional materialization.
* **Pitfalls:** stale caches after model/schema change.
* **DoD:** hit >80%; correctness post‚Äërotation.
* **Checklist:** rotate `embedding_version`; verify.

**4.4 Learning**

* **Do this:** collect feedback; tune ranker; propose templates/indexes.
* **Pitfalls:** training on noisy feedback without guardrails.
* **DoD:** uplift (NDCG) on held‚Äëout set.
* **Checklist:** offline eval; A/B flags.

---

## Phase 5

**5.1 External**

* **Do this:** connectors; webhooks/poll; queue; circuit breakers.
* **Pitfalls:** token scopes; API rate limits.
* **DoD:** steady ingestion; degraded mode OK.
* **Checklist:** throttle tests; backoff observed.

**5.2 Monitoring**

* **Do this:** Prom/Grafana; OTel; alerts; runbooks.
* **Pitfalls:** high‚Äëcardinality labels; missing exemplars.
* **DoD:** on‚Äëcall diagnoses in <10m.
* **Checklist:** alert drill passes.

**5.3 Testing framework**

* **Do this:** **no‚Äëmocks** unit/integration/E2E/perf/security/chaos; determinism checks; CI gates.
* **Pitfalls:** accidental mocking via fixtures.
* **DoD:** CI green; reproducible tests on live stack.
* **Checklist:** artifacts in `/reports/phase-5`.

**5.4 Production**

* **Do this:** blue/green, canary; backups; DR drills.
* **Pitfalls:** partial rollbacks leaving schema mismatches.
* **DoD:** canary 5% for 1h; DR RTO 1h, RPO 15m.
* **Checklist:** rollback & DR drill evidence.

---

# 4) `/docs/pseudocode-reference.md` ‚Äî **Pseudocode Reference (v2, canonical)**

This is the consolidated pseudocode for **every phase/task (1.1 ‚Üí 5.4)**: templates‚Äëfirst NL‚ÜíCypher, plan‚Äëgated validator, hybrid retrieval, provenance‚Äëfirst ingestion, configurable vectors, versioned caches, OTel, chaos tests, DR drills, and phase gates.
*(For brevity here, it‚Äôs the same content you approved previously, aligned 1.1‚Üí5.4. If you‚Äôd like me to paste it verbatim again, say the word and I‚Äôll include the full text inline.)*

---

# 5) PR stubs & file scaffolds (per phase/task)

> Use the script below to scaffold directories & placeholder files.
> Each task has: **code stub**, **test stub (no mocks)**, and **report hook**.

### 5.1 Scaffold script (run once)

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -A TASKS=(
  [p1_t1]="src/platform/compose/ docker/ scripts/test/phase1/"
  [p1_t2]="src/mcp_server/ src/shared/observability/"
  [p1_t3]="scripts/neo4j/ src/shared/schema.py"
  [p1_t4]="src/mcp_server/security/ src/shared/audit/"
  [p2_t1]="src/query/planner.py src/query/templates/"
  [p2_t2]="src/mcp_server/validation.py"
  [p2_t3]="src/query/hybrid_search.py src/query/ranking.py"
  [p2_t4]="src/query/response_builder.py"
  [p3_t1]="src/ingestion/parsers/"
  [p3_t2]="src/ingestion/extract/"
  [p3_t3]="src/ingestion/build_graph.py"
  [p3_t4]="src/ingestion/{incremental.py,reconcile.py}"
  [p4_t1]="src/query/templates/advanced/"
  [p4_t2]="src/ops/optimizer.py"
  [p4_t3]="src/shared/cache.py src/ops/warmers/"
  [p4_t4]="src/learning/"
  [p5_t1]="src/connectors/"
  [p5_t2]="deploy/monitoring/"
  [p5_t3]="tests/ ci/ .github/workflows/"
  [p5_t4]="deploy/k8s/ deploy/helm/ ci/cd/"
)

for t in "${!TASKS[@]}"; do
  IFS=' ' read -r -a paths <<< "${TASKS[$t]}"
  for p in "${paths[@]}"; do mkdir -p "$p"; done
  touch "tests/${t}_test.py" "src/${t}_README.md"
done

mkdir -p reports/phase-{1,2,3,4,5}
echo "Scaffold complete."
```

### 5.2 File stubs (illustrative subset)

* `src/mcp_server/main.py` ‚Äî MCP entrypoint (tools, health, metrics).
* `src/mcp_server/validation.py` ‚Äî validator (regex + `EXPLAIN` gates).
* `src/query/planner.py` ‚Äî templates‚Äëfirst NL‚ÜíCypher planner.
* `src/query/templates/{search.cypher, traverse.cypher, ...}`
* `src/query/hybrid_search.py` ‚Äî vector+graph retrieval.
* `src/query/ranking.py` ‚Äî multi‚Äësignal ranker.
* `src/query/response_builder.py` ‚Äî Markdown + JSON with evidence.
* `src/ingestion/parsers/{markdown.py,html.py,notion.py}`
* `src/ingestion/extract/{commands.py,configs.py,procedures.py,...}`
* `src/ingestion/build_graph.py`, `src/ingestion/{incremental.py,reconcile.py}`
* `scripts/neo4j/create_schema.cypher`
* `src/shared/{schema.py,cache.py,config.py,observability/tracing.py,audit/logger.py}`

### 5.3 Test stubs (NO MOCKS) & reports harness

* `tests/p1_t1_compose_test.py` ‚Äî brings up compose, asserts health; writes JUnit & `summary.json`.
* `tests/p2_t2_validator_negative_test.py` ‚Äî executes malicious queries vs live Neo4j; expects blocks.
* `tests/p2_t3_hybrid_perf_test.py` ‚Äî Locust/k6 wrapper to produce P95 metrics CSV.
* `tests/p3_t3_idempotency_test.py` ‚Äî ingest twice; assert stable counts.
* `tests/p4_t3_cache_rotation_test.py` ‚Äî rotate embedding version; assertions on cache invalidation.
* `tests/p5_t3_chaos_test.py` ‚Äî kill vector service; verify degraded operation.

**Helper:** `/scripts/test/run_phase.sh`
Runs tests for a phase, emits `/reports/phase-N/junit.xml` & `/reports/phase-N/summary.json`:

```bash
#!/usr/bin/env bash
set -euo pipefail
PHASE="${1:?phase number required (1..5)}"
pytest -q --maxfail=1 --junitxml="reports/phase-${PHASE}/junit.xml" \
  -k "p${PHASE}_" \
  | tee "reports/phase-${PHASE}/pytest.out"

python scripts/test/summarize.py --phase "${PHASE}" \
  --junit "reports/phase-${PHASE}/junit.xml" \
  --out "reports/phase-${PHASE}/summary.json"
```

**`scripts/test/summarize.py` (schema writer skeleton):**

```python
import json, sys, argparse, time, subprocess, hashlib, os
p=argparse.ArgumentParser(); p.add_argument("--phase"); p.add_argument("--junit"); p.add_argument("--out"); a=p.parse_args()
summary={"phase":a.phase,"date_utc":time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
         "commit": subprocess.check_output(["git","rev-parse","HEAD"]).decode().strip(),
         "results":[], "metrics":{}, "artifacts":["junit.xml"]}
# minimal example: parse JUnit for pass/fail counts (left as exercise to implement fully)
with open(a.out,"w") as f: json.dump(summary,f,indent=2)
print(f"Wrote {a.out}")
```

### 5.4 CI workflow & PR template

**`.github/workflows/ci.yml`** (phase‚Äëaware):

```yaml
name: CI
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - run: docker compose up -d
      - run: make test-phase-1
      - run: make test-phase-2
      - run: make test-phase-3
      - run: make test-phase-4
      - run: make test-phase-5
      - uses: actions/upload-artifact@v4
        with:
          name: reports
          path: reports/
```

**`Makefile`** (key targets):

```makefile
PHASE?=1
up:
\tdocker compose up -d
down:
\tdocker compose down -v
test-phase-%: up
\tbash scripts/test/run_phase.sh $* || (echo "Phase $* failed" && exit 1)
```

**`.github/pull_request_template.md`**

```
# PR Title (Phase X.Y): <feature>

## Scope
- [ ] Implements task X.Y exactly as per /docs/implementation-plan.md
- [ ] No mocks used in tests; hits live stack

## Tests & Artifacts
- [ ] Added tests under tests/pX_tY_*.py
- [ ] Attached /reports/phase-X/junit.xml and summary.json
- [ ] For perf tasks: attached perf CSV and plots

## Phase Gate
- [ ] Meets DoD and Gate criteria for Phase X
```

---

## How to use this pack

1. Documents located under `/docs/` as named.
2. Run the **scaffold script** to create stubs and folders.
3. Implement each task; for every PR, include **reports** for that phase.
4. Advance only when the **Phase Gate** is met (CI must pass, artifacts uploaded).
5. Share `/reports/phase-*/summary.json` & `junit.xml` with me to **verify success**.
