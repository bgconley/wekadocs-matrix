# Core dependencies for Phase 1
# See: /docs/implementation-plan.md â†’ Phase 1

# FastAPI and ASGI server
fastapi>=0.115.0
uvicorn[standard]>=0.30.0
pydantic>=2.7,<3
pydantic-settings>=2.5.2

# Neo4j driver
neo4j==5.26.0

# Qdrant client
qdrant-client==1.16.1

# Redis client
redis>=5.0.3

# Numerical computations (ColBERT scoring, metrics)
numpy>=1.24.0

# File system watcher (Phase 6)
watchdog>=4.0.0

# JWT authentication
pyjwt==2.8.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4

# OpenTelemetry
opentelemetry-api==1.22.0
opentelemetry-sdk==1.22.0
opentelemetry-instrumentation-fastapi==0.43b0
opentelemetry-instrumentation-redis==0.43b0
opentelemetry-exporter-otlp==1.22.0

# Prometheus metrics
prometheus-client==0.19.0

# Configuration and environment
pyyaml==6.0.1
python-dotenv==1.0.0

# Structured logging
structlog==24.1.0
python-json-logger==2.0.7

# HTTP client
httpx>=0.27.0

# Testing (for Phase 1 tests)
pytest==7.4.4
pytest-asyncio==0.23.3
pytest-cov==4.1.0

# Data validation
jsonschema==4.20.0

# Utilities
python-multipart>=0.0.6
aiofiles==23.2.1
orjson>=3.10.0

# Phase 3: Ingestion pipeline dependencies
sentence-transformers==2.7.0
beautifulsoup4==4.12.2
html2text==2024.2.26
markdown==3.5.1

# Phase: markdown-it-py Integration (AST-based parsing with source line mapping)
# markdown-it-py provides SyntaxTreeNode AST and Token.map for source positions
# mdit-py-plugins provides frontmatter, footnote, and other extensions
# linkify-it-py enables URL autolinking in gfm-like preset
markdown-it-py>=3.0.0
mdit-py-plugins>=0.4.0
linkify-it-py>=2.0.0

lxml==4.9.3
mcp[cli]==1.16.0  # MCP SDK pinned for low-level server + Streamable HTTP

# Phase 7C: Additional provider dependencies
# Note: Jina AI and bge-m3-service integrations use REST (httpx already included above)

# Phase 7C Hotfix: Tokenizer service for accurate token counting
# CRITICAL: Use jina-embeddings-v3 tokenizer (XLM-RoBERTa), NOT tiktoken (OpenAI)
transformers>=4.43.0  # HuggingFace tokenizer (primary backend)
tokenizers>=0.15.0    # Fast Rust backend for transformers
sentencepiece>=0.2.0  # Required by XLM-RoBERTa tokenizer
huggingface_hub>=0.23.0  # For model/tokenizer downloads
gliner>=0.2.24

# Phase: Semantic Chunking (Research-aligned chunking approach)
# Chonkie provides semantic boundary detection for chunking
# langchain-text-splitters provides RecursiveCharacterTextSplitter for fallback
chonkie[semantic]>=0.3.0
langchain-text-splitters>=0.3.0
