# Implements Phase 1, Task 1.1 (Docker environment setup)
# See: /docs/spec.md §2 (Architecture)
# See: /docs/implementation-plan.md → Task 1.1 DoD & Tests

version: '3.8'

networks:
  weka-net:
    driver: bridge
    name: weka-net

volumes:
  neo4j-data:
  neo4j-logs:
  qdrant-data:
  redis-data:
  hf-cache:  # Phase 7C: HuggingFace tokenizer cache
  # Tailscale state volumes for sidecar containers
  ts-mcp-server-state:
  ts-ingestion-worker-state:

services:
  neo4j:
    image: neo4j:2025.10.1-community
    container_name: weka-neo4j
    networks:
      - weka-net
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - ./scripts/neo4j:/scripts:ro
    environment:
      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD}
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      - NEO4J_server_memory_heap_initial__size=${NEO4J_HEAP_INITIAL:-1280m}
      - NEO4J_server_memory_heap_max__size=${NEO4J_HEAP_MAX:-2560m}
      - NEO4J_server_memory_pagecache_size=${NEO4J_PAGECACHE:-2G}
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*,gds.*
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_server_db_query__cache__size=50
      - NEO4J_db_transaction_timeout=30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 5G
        reservations:
          cpus: '1'
          memory: 2560M
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "${NEO4J_USER:-neo4j}", "-p", "${NEO4J_PASSWORD}", "RETURN 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  qdrant:
    image: qdrant/qdrant:v1.16.0
    container_name: weka-qdrant
    networks:
      - weka-net
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__LOG_LEVEL=${QDRANT_LOG_LEVEL:-INFO}
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 3G
        reservations:
          cpus: '1'
          memory: 1536M
    healthcheck:
      test: ["CMD-SHELL", "timeout 1 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  redis:
    image: redis:7.2-alpine
    container_name: weka-redis
    networks:
      - weka-net
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory ${REDIS_MAXMEMORY:-768mb}
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "redis-cli", "--pass", "${REDIS_PASSWORD}", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3
      start_period: 5s

  # ============================================================================
  # Tailscale Sidecar Containers
  # These provide Tailnet/MagicDNS access to app containers via network_mode
  # See: https://tailscale.com/kb/1282/docker
  # ============================================================================

  ts-mcp-server:
    image: tailscale/tailscale:latest
    container_name: weka-ts-mcp-server
    hostname: weka-mcp-server
    networks:
      - weka-net
    ports:
      - "${MCP_PORT:-8000}:8000"  # Expose MCP server port through sidecar
    environment:
      - TS_AUTHKEY=tskey-auth-kNYNccYUth11CNTRL-DEUXtBuVL7QiXjKYzK748QaQ9knSK7AtK
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
      - TS_ACCEPT_DNS=true
      - TS_EXTRA_ARGS=--advertise-tags=tag:container --hostname=weka-mcp-server
    volumes:
      - ts-mcp-server-state:/var/lib/tailscale
    devices:
      - /dev/net/tun:/dev/net/tun
    cap_add:
      - net_admin
      - sys_module
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "tailscale", "status", "--json"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  ts-ingestion-worker:
    image: tailscale/tailscale:latest
    container_name: weka-ts-ingestion-worker
    hostname: weka-ingestion-worker
    networks:
      - weka-net
    environment:
      - TS_AUTHKEY=${TS_AUTHKEY}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
      - TS_ACCEPT_DNS=true
      - TS_EXTRA_ARGS=--advertise-tags=tag:container --hostname=weka-ingestion-worker
    volumes:
      - ts-ingestion-worker-state:/var/lib/tailscale
    devices:
      - /dev/net/tun:/dev/net/tun
    cap_add:
      - net_admin
      - sys_module
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "tailscale", "status", "--json"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ============================================================================
  # Application Services
  # ============================================================================

  mcp-server:
    build:
      context: .
      dockerfile: docker/mcp-server.Dockerfile
    container_name: weka-mcp-server
    # Use Tailscale sidecar's network for MagicDNS access to reranker
    network_mode: service:ts-mcp-server
    # Note: ports moved to ts-mcp-server sidecar
    volumes:
      - ./config:/app/config:ro
      - ./src:/app/src:ro
      - ./scripts:/app/scripts:ro
      - ./tests:/app/tests:ro
      - ./reports:/app/reports
      - ./hf-cache:/opt/hf-cache
    env_file:
      - .env.docker
    environment:
      - ENV=${ENV:-development}
      - CONFIG_PATH=/app/config/${ENV:-development}.yaml
      # Phase 7C: Embedding Provider Configuration
      - EMBEDDINGS_PROFILE=${EMBEDDINGS_PROFILE:-bge_m3}
      - EMBEDDING_NAMESPACE_MODE=${EMBEDDING_NAMESPACE_MODE:-profile}
      # Legacy vars cleared to avoid override; set blank to prefer profile-driven config
      - EMBEDDINGS_PROVIDER=${EMBEDDINGS_PROVIDER:-bge-m3-service}
      - EMBEDDINGS_MODEL=${EMBEDDINGS_MODEL:-BAAI/bge-m3}
      - EMBEDDINGS_DIM=${EMBEDDINGS_DIM:-1024}
      - EMBEDDINGS_TASK=${EMBEDDINGS_TASK:-symmetric}
      - BGE_M3_API_URL=${BGE_M3_API_URL:-http://host.docker.internal:9000}
      - GLINER_SERVICE_URL=${GLINER_SERVICE_URL:-http://host.docker.internal:9002}
      - RERANK_PROVIDER=${RERANK_PROVIDER:-bge-reranker-service}
      - RERANK_MODEL=${RERANK_MODEL:-Qwen/Qwen3-Reranker-0.6B}
      - RERANKER_TOKENIZER_ID=${RERANKER_TOKENIZER_ID:-Qwen/Qwen3-Reranker-0.6B}
      - RERANKER_BASE_URL=${RERANKER_BASE_URL:-http://host.docker.internal:9005}
      - RERANKER_TIMEOUT_SECONDS=${RERANKER_TIMEOUT_SECONDS:-120}
      - JINA_API_KEY=${JINA_API_KEY}
      - ANSWER_MODEL=${ANSWER_MODEL:-search-result-formatting}
      # Phase 7C Hotfix: Tokenizer Service Configuration
      - TOKENIZER_BACKEND=hf
      - HF_CACHE=/opt/hf-cache
      - HF_HOME=/opt/hf-cache
      - TRANSFORMERS_OFFLINE=false
      - JINA_SEGMENTER_BASE_URL=https://api.jina.ai/v1/segment
      - SEGMENTER_TOKENIZER_NAME=xlm-roberta-base
      - SEGMENTER_TIMEOUT_MS=5000
      # Guard-Split Chunking Architecture (BGE-M3 model limits)
      - BGE_M3_MAX_INPUT_TOKENS=${BGE_M3_MAX_INPUT_TOKENS:-8192}
      - BGE_M3_SAFE_INPUT_TOKENS=${BGE_M3_SAFE_INPUT_TOKENS:-7500}
      - BGE_M3_GUARD_OVERLAP_TOKENS=${BGE_M3_GUARD_OVERLAP_TOKENS:-200}
      - BGE_M3_OVERSIZE_POLICY=${BGE_M3_OVERSIZE_POLICY:-raise}
      - BGE_M3_MAX_BATCH_TOKENS=${BGE_M3_MAX_BATCH_TOKENS:-7500}
      - SEMANTIC_FALLBACK_OVERLAP_TOKENS=${SEMANTIC_FALLBACK_OVERLAP_TOKENS:-80}
      - EMBED_MAX_TOKENS=${EMBED_MAX_TOKENS:-8000}
      - EMBED_TARGET_TOKENS=${EMBED_TARGET_TOKENS:-7500}
      - EMBED_OVERLAP_TOKENS=${EMBED_OVERLAP_TOKENS:-200}
      - SPLIT_MIN_TOKENS=${SPLIT_MIN_TOKENS:-350}
      - EMBEDDING_NAMESPACE_MODE=${EMBEDDING_NAMESPACE_MODE:-profile}
      - LOG_SPLIT_DECISIONS=true
      - INTEGRITY_CHECK_SAMPLE_RATE=0.05
      # Database connections
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - BM25_INDEX_NAME=${BM25_INDEX_NAME:-chunk_text_index_v2}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_GRPC_PORT=6334
      - REDIS_URI=redis://:${REDIS_PASSWORD}@redis:6379/0
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      # Auth & observability
      - JWT_SECRET=${JWT_SECRET}
      - JWT_ALGORITHM=${JWT_ALGORITHM:-HS256}
      - OTEL_SERVICE_NAME=weka-mcp-server
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=none
      - OTEL_LOGS_EXPORTER=otlp
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      ts-mcp-server:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped

  ingestion-worker:
    build:
      context: .
      dockerfile: docker/ingestion-worker.Dockerfile
    container_name: weka-ingestion-worker
    command: python -m src.ingestion.worker
    # Use Tailscale sidecar's network for MagicDNS access to reranker
    network_mode: service:ts-ingestion-worker
    volumes:
      - ./config:/app/config:ro
      - ./src:/app/src
      - ./tools:/app/tools:ro
      - ./data:/app/data:ro
      - ./hf-cache:/opt/hf-cache
    env_file:
      - .env.docker
    environment:
      - REDIS_URI=redis://:${REDIS_PASSWORD}@redis:6379/0
      - INGEST_NS=ingest
      - ENV=${ENV:-development}
      - CONFIG_PATH=/app/config/${ENV:-development}.yaml
      # Phase 7C: Embedding Provider Configuration
      - EMBEDDINGS_PROFILE=${EMBEDDINGS_PROFILE:-bge_m3}
      - EMBEDDING_NAMESPACE_MODE=${EMBEDDING_NAMESPACE_MODE:-profile}
      - EMBEDDINGS_PROVIDER=${EMBEDDINGS_PROVIDER:-bge-m3-service}
      - EMBEDDINGS_MODEL=${EMBEDDINGS_MODEL:-BAAI/bge-m3}
      - EMBEDDINGS_DIM=${EMBEDDINGS_DIM:-1024}
      - EMBEDDINGS_TASK=${EMBEDDINGS_TASK:-symmetric}
      - BGE_M3_API_URL=${BGE_M3_API_URL:-http://host.docker.internal:9000}
      - GLINER_SERVICE_URL=${GLINER_SERVICE_URL:-http://host.docker.internal:9002}
      - RERANK_PROVIDER=${RERANK_PROVIDER:-bge-reranker-service}
      - RERANK_MODEL=${RERANK_MODEL:-Qwen/Qwen3-Reranker-0.6B}
      - RERANKER_TOKENIZER_ID=${RERANKER_TOKENIZER_ID:-Qwen/Qwen3-Reranker-0.6B}
      - RERANKER_BASE_URL=${RERANKER_BASE_URL:-http://host.docker.internal:9005}
      - RERANKER_TIMEOUT_SECONDS=${RERANKER_TIMEOUT_SECONDS:-120}
      - JINA_API_KEY=${JINA_API_KEY}
      # Phase 7C Hotfix: Tokenizer Service Configuration
      - TOKENIZER_BACKEND=hf
      - HF_CACHE=/opt/hf-cache
      - HF_HOME=/opt/hf-cache
      - TRANSFORMERS_OFFLINE=false
      - JINA_SEGMENTER_BASE_URL=https://api.jina.ai/v1/segment
      - SEGMENTER_TOKENIZER_NAME=xlm-roberta-base
      - SEGMENTER_TIMEOUT_MS=5000
      # Guard-Split Chunking Architecture (BGE-M3 model limits)
      - BGE_M3_MAX_INPUT_TOKENS=${BGE_M3_MAX_INPUT_TOKENS:-8192}
      - BGE_M3_SAFE_INPUT_TOKENS=${BGE_M3_SAFE_INPUT_TOKENS:-7500}
      - BGE_M3_GUARD_OVERLAP_TOKENS=${BGE_M3_GUARD_OVERLAP_TOKENS:-200}
      - BGE_M3_OVERSIZE_POLICY=${BGE_M3_OVERSIZE_POLICY:-raise}
      - BGE_M3_MAX_BATCH_TOKENS=${BGE_M3_MAX_BATCH_TOKENS:-7500}
      - SEMANTIC_FALLBACK_OVERLAP_TOKENS=${SEMANTIC_FALLBACK_OVERLAP_TOKENS:-80}
      - EMBED_MAX_TOKENS=${EMBED_MAX_TOKENS:-8000}
      - EMBED_TARGET_TOKENS=${EMBED_TARGET_TOKENS:-7500}
      - EMBED_OVERLAP_TOKENS=${EMBED_OVERLAP_TOKENS:-200}
      - SPLIT_MIN_TOKENS=${SPLIT_MIN_TOKENS:-350}
      - EMBEDDING_NAMESPACE_MODE=${EMBEDDING_NAMESPACE_MODE:-profile}
      - LOG_SPLIT_DECISIONS=true
      - INTEGRITY_CHECK_SAMPLE_RATE=0.05
      # Database connections
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_GRPC_PORT=6334
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      # Phase 7E-2: Chunk Assembler Configuration
      - CHUNK_ASSEMBLER=${CHUNK_ASSEMBLER:-structured}
      - COMBINE_MIN_TOKENS=${COMBINE_MIN_TOKENS:-350}
      - COMBINE_TARGET_TOKENS=${COMBINE_TARGET_TOKENS:-500}
      - COMBINE_MAX_TOKENS=${COMBINE_MAX_TOKENS:-750}
      - COMBINE_MAX_SECTIONS=${COMBINE_MAX_SECTIONS:-4}
      - COMBINE_RESPECT_MAJOR_LEVELS=${COMBINE_RESPECT_MAJOR_LEVELS:-true}
      - COMBINE_STOP_AT_LEVEL=${COMBINE_STOP_AT_LEVEL:-2}
      - COMBINE_BREAK_KEYWORDS=${COMBINE_BREAK_KEYWORDS:-faq|faqs|glossary|reference|api reference|cli reference|changelog|release notes|troubleshooting}
      - COMBINE_DEBUG=${COMBINE_DEBUG:-false}
      # Phase 7E-5: Disable doc_fallback and microdoc stubs (vector-only mode)
      - COMBINE_DOC_FALLBACK_ENABLED=false
      - COMBINE_MICRODOC_ENABLED=false
      # Phase 7E-3: Cache Invalidation Configuration
      - CACHE_MODE=epoch
      - CACHE_NS=rag:v1
      - CACHE_REDIS_URI=redis://:${REDIS_PASSWORD}@redis:6379/0
      # Auth & security
      - JWT_SECRET=${JWT_SECRET}
      - JWT_ALGORITHM=${JWT_ALGORITHM:-HS256}
      # OTEL Observability (Phase LGTM)
      - OTEL_SERVICE_NAME=weka-ingestion-worker
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=none
      - OTEL_LOGS_EXPORTER=otlp
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      ts-ingestion-worker:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 3584M
        reservations:
          cpus: '1'
          memory: 1792M
    restart: unless-stopped

  # Phase 6: Auto-Ingestion Service (Task 6.1)
  ingestion-service:
    build:
      context: .
      dockerfile: docker/ingestion-service.Dockerfile
    container_name: weka-ingestion-service
    command: python -m src.ingestion.auto.service
    networks:
      - weka-net
    ports:
      - "8081:8081"  # Health/metrics/ready endpoints
    volumes:
      - ./config:/app/config:ro
      - ./src:/app/src
      - ./data:/app/data
      - ./hf-cache:/opt/hf-cache
    env_file:
      - .env.docker
    environment:
      - REDIS_URI=redis://:${REDIS_PASSWORD}@redis:6379/0
      - INGEST_NS=ingest
      - INGEST_WATCH_DIR=/app/data/ingest
      - INGEST_PORT=8081
      - ENV=${ENV:-development}
      - CONFIG_PATH=/app/config/${ENV:-development}.yaml
      # Phase 7C: Embedding Provider Configuration
      - EMBEDDINGS_PROFILE=${EMBEDDINGS_PROFILE:-bge_m3}
      - EMBEDDING_NAMESPACE_MODE=${EMBEDDING_NAMESPACE_MODE:-profile}
      - EMBEDDINGS_PROVIDER=${EMBEDDINGS_PROVIDER:-bge-m3-service}
      - EMBEDDINGS_MODEL=${EMBEDDINGS_MODEL:-BAAI/bge-m3}
      - EMBEDDINGS_DIM=${EMBEDDINGS_DIM:-1024}
      - EMBEDDINGS_TASK=${EMBEDDINGS_TASK:-symmetric}
      - BGE_M3_API_URL=${BGE_M3_API_URL:-http://host.docker.internal:9000}
      - GLINER_SERVICE_URL=${GLINER_SERVICE_URL:-http://host.docker.internal:9002}
      - RERANK_PROVIDER=${RERANK_PROVIDER:-bge-reranker-service}
      - RERANK_MODEL=${RERANK_MODEL:-Qwen/Qwen3-Reranker-0.6B}
      - RERANKER_TOKENIZER_ID=${RERANKER_TOKENIZER_ID:-Qwen/Qwen3-Reranker-0.6B}
      - RERANKER_BASE_URL=${RERANKER_BASE_URL:-http://host.docker.internal:9005}
      - RERANKER_TIMEOUT_SECONDS=${RERANKER_TIMEOUT_SECONDS:-120}
      - JINA_API_KEY=${JINA_API_KEY}
      # Phase 7C Hotfix: Tokenizer Service Configuration
      - TOKENIZER_BACKEND=hf
      - HF_CACHE=/opt/hf-cache
      - HF_HOME=/opt/hf-cache
      - TRANSFORMERS_OFFLINE=false
      - JINA_SEGMENTER_BASE_URL=https://api.jina.ai/v1/segment
      - SEGMENTER_TOKENIZER_NAME=xlm-roberta-base
      - SEGMENTER_TIMEOUT_MS=5000
      # Guard-Split Chunking Architecture (BGE-M3 model limits)
      - BGE_M3_MAX_INPUT_TOKENS=${BGE_M3_MAX_INPUT_TOKENS:-8192}
      - BGE_M3_SAFE_INPUT_TOKENS=${BGE_M3_SAFE_INPUT_TOKENS:-7500}
      - BGE_M3_GUARD_OVERLAP_TOKENS=${BGE_M3_GUARD_OVERLAP_TOKENS:-200}
      - BGE_M3_OVERSIZE_POLICY=${BGE_M3_OVERSIZE_POLICY:-raise}
      - BGE_M3_MAX_BATCH_TOKENS=${BGE_M3_MAX_BATCH_TOKENS:-7500}
      - SEMANTIC_FALLBACK_OVERLAP_TOKENS=${SEMANTIC_FALLBACK_OVERLAP_TOKENS:-80}
      - EMBED_MAX_TOKENS=${EMBED_MAX_TOKENS:-8000}
      - EMBED_TARGET_TOKENS=${EMBED_TARGET_TOKENS:-7500}
      - EMBED_OVERLAP_TOKENS=${EMBED_OVERLAP_TOKENS:-200}
      - SPLIT_MIN_TOKENS=${SPLIT_MIN_TOKENS:-350}
      - EMBEDDING_NAMESPACE_MODE=${EMBEDDING_NAMESPACE_MODE:-profile}
      - LOG_SPLIT_DECISIONS=true
      - INTEGRITY_CHECK_SAMPLE_RATE=0.05
      # Database connections
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      # Phase 7E-2: Chunk Assembler Configuration
      - CHUNK_ASSEMBLER=${CHUNK_ASSEMBLER:-structured}
      - COMBINE_MIN_TOKENS=${COMBINE_MIN_TOKENS:-350}
      - COMBINE_TARGET_TOKENS=${COMBINE_TARGET_TOKENS:-500}
      - COMBINE_MAX_TOKENS=${COMBINE_MAX_TOKENS:-750}
      - COMBINE_MAX_SECTIONS=${COMBINE_MAX_SECTIONS:-4}
      - COMBINE_RESPECT_MAJOR_LEVELS=${COMBINE_RESPECT_MAJOR_LEVELS:-true}
      - COMBINE_STOP_AT_LEVEL=${COMBINE_STOP_AT_LEVEL:-2}
      - COMBINE_BREAK_KEYWORDS=${COMBINE_BREAK_KEYWORDS:-faq|faqs|glossary|reference|api reference|cli reference|changelog|release notes|troubleshooting}
      # Phase 7E-5: Disable doc_fallback and microdoc stubs (vector-only mode)
      - COMBINE_DOC_FALLBACK_ENABLED=false
      - COMBINE_MICRODOC_ENABLED=false
      # Phase 7E-3: Cache Invalidation Configuration
      - CACHE_MODE=epoch
      - CACHE_NS=rag:v1
      - CACHE_REDIS_URI=redis://:${REDIS_PASSWORD}@redis:6379/0
      # OTEL Observability (Phase LGTM)
      - OTEL_SERVICE_NAME=weka-ingestion-service
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=none
      - OTEL_LOGS_EXPORTER=otlp
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped

  # LGTM Observability: Grafana Alloy (unified telemetry collector)
  # Forwards logs, traces, and metrics to GCP LGTM stack via Tailscale
  alloy:
    image: grafana/alloy:v1.4.0
    container_name: weka-alloy
    networks:
      - weka-net
    ports:
      - "12345:12345"  # Alloy UI
      - "4317:4317"    # OTLP gRPC
      - "4318:4318"    # OTLP HTTP
    volumes:
      - ./config/alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command:
      - run
      - --server.http.listen-addr=0.0.0.0:12345
      - --storage.path=/var/lib/alloy
      - /etc/alloy/config.alloy
    environment:
      - HOSTNAME=${HOSTNAME:-wekadocs-dev}
      # GCP LGTM endpoints (via Tailscale)
      - LOKI_ENDPOINT=${LOKI_ENDPOINT:-http://10.10.0.5:3100/loki/api/v1/push}
      - TEMPO_ENDPOINT=${TEMPO_ENDPOINT:-10.10.0.5:4317}
      - MIMIR_ENDPOINT=${MIMIR_ENDPOINT:-http://10.10.0.5:9009/api/v1/push}
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/12345' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      - "metrics.scrape=false"  # Don't scrape Alloy itself circularly
